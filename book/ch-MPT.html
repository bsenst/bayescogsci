<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 18 Multinomial processing trees | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 18 Multinomial processing trees | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 18 Multinomial processing trees | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2022-09-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-cogmod.html"/>
<link rel="next" href="ch-mixture.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script>
// FOLD code from 
// https://github.com/bblodfon/rtemps/blob/master/docs/bookdown-lite/hide_code.html
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // if code block has been labeled with class `fold-show`, show the code on init!
    var classList = $(this).attr('class').split(/\s+/);
    for (var i = 0; i < classList.length; i++) {
    if (classList[i] === 'fold-show') {
        show = true;
      }
    }

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // hack: return show to false, otherwise all next codeBlocks will be shown!
    show = false;

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science (DRAFT)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i>Who is this book for?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#developing-the-right-mindset-for-this-book"><i class="fa fa-check"></i>Developing the right mindset for this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book-anyway"><i class="fa fa-check"></i>Why read this book anyway?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#some-conventions-used-in-this-book"><i class="fa fa-check"></i>Some conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-materials"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-needed"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#introprob"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#condprob"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#the-law-of-total-probability"><i class="fa fa-check"></i><b>1.3</b> The law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-binomialcloze"><i class="fa fa-check"></i><b>1.4</b> Discrete random variables: An example using the binomial distribution</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ch-intro.html"><a href="ch-intro.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch-intro.html"><a href="ch-intro.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-intro.html"><a href="ch-intro.html#continuous-random-variables-an-example-using-the-normal-distribution"><i class="fa fa-check"></i><b>1.5</b> Continuous random variables: An example using the normal distribution</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="ch-intro.html"><a href="ch-intro.html#an-important-distinction-probability-vs.-density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-intro.html"><a href="ch-intro.html#truncating-a-normal-distribution"><i class="fa fa-check"></i><b>1.5.2</b> Truncating a normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-intro.html"><a href="ch-intro.html#bivariate-and-multivariate-distributions"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="ch-intro.html"><a href="ch-intro.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1: Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-contbivar"><i class="fa fa-check"></i><b>1.6.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate simulated bivariate (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-intro.html"><a href="ch-intro.html#sec-marginal"><i class="fa fa-check"></i><b>1.7</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="ch-intro.html"><a href="ch-intro.html#summary-of-useful-r-functions-relating-to-distributions"><i class="fa fa-check"></i><b>1.8</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.9" data-path="ch-intro.html"><a href="ch-intro.html#summary"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="ch-intro.html"><a href="ch-intro.html#further-reading"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
<li class="chapter" data-level="1.11" data-path="ch-intro.html"><a href="ch-intro.html#sec-Foundationsexercises"><i class="fa fa-check"></i><b>1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#bayes-rule"><i class="fa fa-check"></i><b>2.1</b> Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-analytical"><i class="fa fa-check"></i><b>2.2</b> Deriving the posterior using Bayes’ rule: An analytical example</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using Bayes’ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#visualizing-the-prior-likelihood-and-the-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and the posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch-introBDA.html"><a href="ch-introBDA.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch-introBDA.html"><a href="ch-introBDA.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#further-reading-1"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
<li class="chapter" data-level="2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-BDAexercises"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sampling"><i class="fa fa-check"></i><b>3.1</b> Deriving the posterior through sampling</a></li>
<li class="chapter" data-level="3.2" data-path="ch-compbda.html"><a href="ch-compbda.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.2</b> Bayesian Regression Models using Stan: brms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-simplenormal"><i class="fa fa-check"></i><b>3.2.1</b> A simple linear model: A single subject pressing a button repeatedly</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-priorpred"><i class="fa fa-check"></i><b>3.3</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.4" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sensitivity"><i class="fa fa-check"></i><b>3.4</b> The influence of priors: sensitivity analysis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch-compbda.html"><a href="ch-compbda.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.4.1</b> Flat, uninformative priors</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-compbda.html"><a href="ch-compbda.html#regularizing-priors"><i class="fa fa-check"></i><b>3.4.2</b> Regularizing priors</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-compbda.html"><a href="ch-compbda.html#principled-priors"><i class="fa fa-check"></i><b>3.4.3</b> Principled priors</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-compbda.html"><a href="ch-compbda.html#informative-priors"><i class="fa fa-check"></i><b>3.4.4</b> Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-revisit"><i class="fa fa-check"></i><b>3.5</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.6" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ppd"><i class="fa fa-check"></i><b>3.6</b> Posterior predictive distribution</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="ch-compbda.html"><a href="ch-compbda.html#comparing-different-likelihoods"><i class="fa fa-check"></i><b>3.6.1</b> Comparing different likelihoods</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lnfirst"><i class="fa fa-check"></i><b>3.6.2</b> The log-normal likelihood</a></li>
<li class="chapter" data-level="3.6.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lognormal"><i class="fa fa-check"></i><b>3.6.3</b> Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="ch-compbda.html"><a href="ch-compbda.html#list-of-the-most-important-commands"><i class="fa fa-check"></i><b>3.7</b> List of the most important commands</a></li>
<li class="chapter" data-level="3.8" data-path="ch-compbda.html"><a href="ch-compbda.html#summary-2"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
<li class="chapter" data-level="3.9" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ch3furtherreading"><i class="fa fa-check"></i><b>3.9</b> Further reading</a></li>
<li class="chapter" data-level="3.10" data-path="ch-compbda.html"><a href="ch-compbda.html#ex:compbda"><i class="fa fa-check"></i><b>3.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupil"><i class="fa fa-check"></i><b>4.1</b> A first linear regression: Does attentional load affect pupil size?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b> Likelihood and priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-trial"><i class="fa fa-check"></i><b>4.2</b> Log-normal model: Does trial affect response times?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.2.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-reg.html"><a href="ch-reg.html#sec-logistic"><i class="fa fa-check"></i><b>4.3</b> Logistic regression: Does set size affect free recall?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ch-reg.html"><a href="ch-reg.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-priorslogisticregression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy-1"><i class="fa fa-check"></i><b>4.3.5</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-reg.html"><a href="ch-reg.html#summary-3"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="ch-reg.html"><a href="ch-reg.html#sec-ch4furtherreading"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="ch-reg.html"><a href="ch-reg.html#sec-LMexercises"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#exchangeability-and-hierarchical-models"><i class="fa fa-check"></i><b>5.1</b> Exchangeability and hierarchical models</a></li>
<li class="chapter" data-level="5.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-N400hierarchical"><i class="fa fa-check"></i><b>5.2</b> A hierarchical model with a normal likelihood: The N400 effect</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-Mcp"><i class="fa fa-check"></i><b>5.2.1</b> Complete pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.2.2</b> No pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.2.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-uncorrelated"><i class="fa fa-check"></i><b>5.2.3</b> Varying intercepts and varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.2.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-mcvivs"><i class="fa fa-check"></i><b>5.2.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.2.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-sih"><i class="fa fa-check"></i><b>5.2.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.2.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-distrmodel"><i class="fa fa-check"></i><b>5.2.6</b> Beyond the maximal model–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-stroop"><i class="fa fa-check"></i><b>5.3</b> A hierarchical log-normal model: The Stroop effect</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.3.1</b> A correlated varying intercept varying slopes log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort"><i class="fa fa-check"></i><b>5.4</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#summary-4"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
<li class="chapter" data-level="5.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#further-reading-2"><i class="fa fa-check"></i><b>5.6</b> Further reading</a></li>
<li class="chapter" data-level="5.7" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-HLMexercises"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>6</b> The Art and Science of Prior Elicitation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch-priors.html"><a href="ch-priors.html#sec-simpleexamplepriors"><i class="fa fa-check"></i><b>6.1</b> Eliciting priors from oneself for a self-paced reading study: A simple example</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ch-priors.html"><a href="ch-priors.html#an-example-english-relative-clauses"><i class="fa fa-check"></i><b>6.1.1</b> An example: English relative clauses</a></li>
<li class="chapter" data-level="6.1.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-intercept"><i class="fa fa-check"></i><b>6.1.2</b> Eliciting a prior for the intercept</a></li>
<li class="chapter" data-level="6.1.3" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-slope"><i class="fa fa-check"></i><b>6.1.3</b> Eliciting a prior for the slope</a></li>
<li class="chapter" data-level="6.1.4" data-path="ch-priors.html"><a href="ch-priors.html#sec-varcomppriors"><i class="fa fa-check"></i><b>6.1.4</b> Eliciting priors for the variance components</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>6.2</b> Eliciting priors from experts</a></li>
<li class="chapter" data-level="6.3" data-path="ch-priors.html"><a href="ch-priors.html#deriving-priors-from-meta-analyses"><i class="fa fa-check"></i><b>6.3</b> Deriving priors from meta-analyses</a></li>
<li class="chapter" data-level="6.4" data-path="ch-priors.html"><a href="ch-priors.html#using-previous-experiments-posteriors-as-priors-for-a-new-study"><i class="fa fa-check"></i><b>6.4</b> Using previous experiments’ posteriors as priors for a new study</a></li>
<li class="chapter" data-level="6.5" data-path="ch-priors.html"><a href="ch-priors.html#summary-5"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="ch-priors.html"><a href="ch-priors.html#further-reading-3"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>7</b> Workflow</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-workflow.html"><a href="ch-workflow.html#model-building"><i class="fa fa-check"></i><b>7.1</b> Model building</a></li>
<li class="chapter" data-level="7.2" data-path="ch-workflow.html"><a href="ch-workflow.html#principled-questions-on-a-model"><i class="fa fa-check"></i><b>7.2</b> Principled questions on a model</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ch-workflow.html"><a href="ch-workflow.html#prior-predictive-checks-checking-consistency-with-domain-expertise"><i class="fa fa-check"></i><b>7.2.1</b> Prior predictive checks: Checking consistency with domain expertise</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch-workflow.html"><a href="ch-workflow.html#computational-faithfulness-testing-for-correct-posterior-approximations"><i class="fa fa-check"></i><b>7.2.2</b> Computational faithfulness: Testing for correct posterior approximations</a></li>
<li class="chapter" data-level="7.2.3" data-path="ch-workflow.html"><a href="ch-workflow.html#model-sensitivity"><i class="fa fa-check"></i><b>7.2.3</b> Model sensitivity</a></li>
<li class="chapter" data-level="7.2.4" data-path="ch-workflow.html"><a href="ch-workflow.html#posterior-predictive-checks-does-the-model-adequately-capture-the-data"><i class="fa fa-check"></i><b>7.2.4</b> Posterior predictive checks: Does the model adequately capture the data?</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-workflow.html"><a href="ch-workflow.html#exemplary-data-analysis"><i class="fa fa-check"></i><b>7.3</b> Exemplary data analysis</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ch-workflow.html"><a href="ch-workflow.html#prior-predictive-checks"><i class="fa fa-check"></i><b>7.3.1</b> Prior predictive checks</a></li>
<li class="chapter" data-level="7.3.2" data-path="ch-workflow.html"><a href="ch-workflow.html#adjusting-priors"><i class="fa fa-check"></i><b>7.3.2</b> Adjusting priors</a></li>
<li class="chapter" data-level="7.3.3" data-path="ch-workflow.html"><a href="ch-workflow.html#computational-faithfulness-and-model-sensitivity"><i class="fa fa-check"></i><b>7.3.3</b> Computational faithfulness and model sensitivity</a></li>
<li class="chapter" data-level="7.3.4" data-path="ch-workflow.html"><a href="ch-workflow.html#posterior-predictive-checks-model-adequacy"><i class="fa fa-check"></i><b>7.3.4</b> Posterior predictive checks: Model adequacy</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch-workflow.html"><a href="ch-workflow.html#summary-6"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="ch-workflow.html"><a href="ch-workflow.html#further-reading-4"><i class="fa fa-check"></i><b>7.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>8</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-contr.html"><a href="ch-contr.html#basic-concepts-illustrated-using-a-two-level-factor"><i class="fa fa-check"></i><b>8.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ch-contr.html"><a href="ch-contr.html#treatmentcontrasts"><i class="fa fa-check"></i><b>8.1.1</b> Default contrast coding: Treatment contrasts</a></li>
<li class="chapter" data-level="8.1.2" data-path="ch-contr.html"><a href="ch-contr.html#inverseMatrix"><i class="fa fa-check"></i><b>8.1.2</b> Defining comparisons</a></li>
<li class="chapter" data-level="8.1.3" data-path="ch-contr.html"><a href="ch-contr.html#effectcoding"><i class="fa fa-check"></i><b>8.1.3</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.1.4" data-path="ch-contr.html"><a href="ch-contr.html#sec-cellMeans"><i class="fa fa-check"></i><b>8.1.4</b> Cell means parameterization and posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix-illustrated-with-a-three-level-factor"><i class="fa fa-check"></i><b>8.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ch-contr.html"><a href="ch-contr.html#sumcontrasts"><i class="fa fa-check"></i><b>8.2.1</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.2.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The hypothesis matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="ch-contr.html"><a href="ch-contr.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>8.2.3</b> Generating contrasts: The <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ch-contr.html"><a href="ch-contr.html#sec-4levelFactor"><i class="fa fa-check"></i><b>8.3</b> Other types of contrasts: illustration with a factor with four levels</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ch-contr.html"><a href="ch-contr.html#repeatedcontrasts"><i class="fa fa-check"></i><b>8.3.1</b> Repeated contrasts</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-contr.html"><a href="ch-contr.html#helmertcontrasts"><i class="fa fa-check"></i><b>8.3.2</b> Helmert contrasts</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-contr.html"><a href="ch-contr.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>8.3.3</b> Contrasts in linear regression analysis: The design or model matrix</a></li>
<li class="chapter" data-level="8.3.4" data-path="ch-contr.html"><a href="ch-contr.html#polynomialContrasts"><i class="fa fa-check"></i><b>8.3.4</b> Polynomial contrasts</a></li>
<li class="chapter" data-level="8.3.5" data-path="ch-contr.html"><a href="ch-contr.html#an-alternative-to-contrasts-monotonic-effects"><i class="fa fa-check"></i><b>8.3.5</b> An alternative to contrasts: monotonic effects</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-contr.html"><a href="ch-contr.html#nonOrthogonal"><i class="fa fa-check"></i><b>8.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ch-contr.html"><a href="ch-contr.html#centered-contrasts"><i class="fa fa-check"></i><b>8.4.1</b> Centered contrasts</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-contr.html"><a href="ch-contr.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>8.4.2</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="8.4.3" data-path="ch-contr.html"><a href="ch-contr.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>8.4.3</b> The role of the intercept in non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-contr.html"><a href="ch-contr.html#computing-condition-means-from-estimated-contrasts"><i class="fa fa-check"></i><b>8.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="8.6" data-path="ch-contr.html"><a href="ch-contr.html#summary-7"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
<li class="chapter" data-level="8.7" data-path="ch-contr.html"><a href="ch-contr.html#further-reading-5"><i class="fa fa-check"></i><b>8.7</b> Further reading</a></li>
<li class="chapter" data-level="8.8" data-path="ch-contr.html"><a href="ch-contr.html#sec-Contrastsexercises"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>9</b> Contrast coding for designs with two predictor variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-MR-ANOVA"><i class="fa fa-check"></i><b>9.1</b> Contrast coding in a factorial <span class="math inline">\(2 \times 2\)</span> design</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#nestedEffects"><i class="fa fa-check"></i><b>9.1.1</b> Nested effects</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>9.1.2</b> Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-contrast-covariate"><i class="fa fa-check"></i><b>9.2</b> One factor and one covariate</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>9.2.1</b> Estimating a group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>9.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-interactions-NLM"><i class="fa fa-check"></i><b>9.3</b> Interactions in generalized linear models (with non-linear link functions) and non-linear models</a></li>
<li class="chapter" data-level="9.4" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#summary-8"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#further-reading-6"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
<li class="chapter" data-level="9.6" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-Contrasts2x2exercises"><i class="fa fa-check"></i><b>9.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="10" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>10</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-introstan.html"><a href="ch-introstan.html#stan-syntax"><i class="fa fa-check"></i><b>10.1</b> Stan syntax</a></li>
<li class="chapter" data-level="10.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-firststan"><i class="fa fa-check"></i><b>10.2</b> A first simple example with Stan: Normal likelihood</a></li>
<li class="chapter" data-level="10.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-clozestan"><i class="fa fa-check"></i><b>10.3</b> Another simple example: Cloze probability with Stan with the binomial likelihood</a></li>
<li class="chapter" data-level="10.4" data-path="ch-introstan.html"><a href="ch-introstan.html#regression-models-in-stan"><i class="fa fa-check"></i><b>10.4</b> Regression models in Stan</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-pupilstan"><i class="fa fa-check"></i><b>10.4.1</b> A first linear regression in Stan: Does attentional load affect pupil size?</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-interstan"><i class="fa fa-check"></i><b>10.4.2</b> Interactions in Stan: Does attentional load interact with trial number affecting pupil size?</a></li>
<li class="chapter" data-level="10.4.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-logisticstan"><i class="fa fa-check"></i><b>10.4.3</b> Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-introstan.html"><a href="ch-introstan.html#summary-9"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="ch-introstan.html"><a href="ch-introstan.html#further-reading-7"><i class="fa fa-check"></i><b>10.6</b> Further reading</a></li>
<li class="chapter" data-level="10.7" data-path="ch-introstan.html"><a href="ch-introstan.html#exercises"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>11</b> Complex models and reparametrization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-hierstan"><i class="fa fa-check"></i><b>11.1</b> Hierarchical models with Stan</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>11.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-uncorrstan"><i class="fa fa-check"></i><b>11.1.2</b> Uncorrelated varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="11.1.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-corrstan"><i class="fa fa-check"></i><b>11.1.3</b> Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="11.1.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-crosscorrstan"><i class="fa fa-check"></i><b>11.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#summary-10"><i class="fa fa-check"></i><b>11.2</b> Summary</a></li>
<li class="chapter" data-level="11.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#further-reading-8"><i class="fa fa-check"></i><b>11.3</b> Further reading</a></li>
<li class="chapter" data-level="11.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#exercises-1"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>12</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-custom.html"><a href="ch-custom.html#sec-change"><i class="fa fa-check"></i><b>12.1</b> A change of variables with the reciprocal normal distribution</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="ch-custom.html"><a href="ch-custom.html#scaling-a-probability-density-with-the-jacobian-adjustment"><i class="fa fa-check"></i><b>12.1.1</b> Scaling a probability density with the Jacobian adjustment</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ch-custom.html"><a href="ch-custom.html#sec-validSBC"><i class="fa fa-check"></i><b>12.2</b> Validation of a computed posterior distribution</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ch-custom.html"><a href="ch-custom.html#the-simulation-based-calibration-procedure"><i class="fa fa-check"></i><b>12.2.1</b> The simulation-based calibration procedure</a></li>
<li class="chapter" data-level="12.2.2" data-path="ch-custom.html"><a href="ch-custom.html#simulation-based-calibration-revealing-a-problem"><i class="fa fa-check"></i><b>12.2.2</b> Simulation-based calibration revealing a problem</a></li>
<li class="chapter" data-level="12.2.3" data-path="ch-custom.html"><a href="ch-custom.html#issues-and-limitation-of-simulation-based-calibration"><i class="fa fa-check"></i><b>12.2.3</b> Issues and limitation of simulation-based calibration</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch-custom.html"><a href="ch-custom.html#a-custom-distribution-re-implementing-the-exponential-distribution-manually"><i class="fa fa-check"></i><b>12.3</b> A custom distribution: Re-implementing the exponential distribution manually</a></li>
<li class="chapter" data-level="12.4" data-path="ch-custom.html"><a href="ch-custom.html#summary-11"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
<li class="chapter" data-level="12.5" data-path="ch-custom.html"><a href="ch-custom.html#further-reading-9"><i class="fa fa-check"></i><b>12.5</b> Further reading</a></li>
<li class="chapter" data-level="12.6" data-path="ch-custom.html"><a href="ch-custom.html#sec-customexercises"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Other useful models</b></span></li>
<li class="chapter" data-level="13" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and measurement error models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch-remame.html"><a href="ch-remame.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ch-remame.html"><a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>13.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-remame.html"><a href="ch-remame.html#measurement-error-models"><i class="fa fa-check"></i><b>13.2</b> Measurement-error models</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ch-remame.html"><a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency"><i class="fa fa-check"></i><b>13.2.1</b> Accounting for measurement error in individual differences in working memory capacity and reading fluency</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-remame.html"><a href="ch-remame.html#summary-12"><i class="fa fa-check"></i><b>13.3</b> Summary</a></li>
<li class="chapter" data-level="13.4" data-path="ch-remame.html"><a href="ch-remame.html#further-reading-10"><i class="fa fa-check"></i><b>13.4</b> Further reading</a></li>
<li class="chapter" data-level="13.5" data-path="ch-remame.html"><a href="ch-remame.html#sec-REMAMEexercises"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Model comparison and hypothesis testing</b></span></li>
<li class="chapter" data-level="14" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>14</b> Introduction to model comparison</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-comparison.html"><a href="ch-comparison.html#further-reading-11"><i class="fa fa-check"></i><b>14.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>15</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-bf.html"><a href="ch-bf.html#hypothesis-testing-using-the-bayes-factor"><i class="fa fa-check"></i><b>15.1</b> Hypothesis testing using the Bayes factor</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="ch-bf.html"><a href="ch-bf.html#marginal-likelihood"><i class="fa fa-check"></i><b>15.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="15.1.2" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factor"><i class="fa fa-check"></i><b>15.1.2</b> Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-N400BF"><i class="fa fa-check"></i><b>15.2</b> Examining the N400 effect with Bayes factor</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="ch-bf.html"><a href="ch-bf.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>15.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="15.2.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFnonnested"><i class="fa fa-check"></i><b>15.2.2</b> Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ch-bf.html"><a href="ch-bf.html#the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest"><i class="fa fa-check"></i><b>15.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a></li>
<li class="chapter" data-level="15.4" data-path="ch-bf.html"><a href="ch-bf.html#sec-stanBF"><i class="fa fa-check"></i><b>15.4</b> Bayes factor in Stan</a></li>
<li class="chapter" data-level="15.5" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-and-in-practice"><i class="fa fa-check"></i><b>15.5</b> Bayes factors in theory and in practice</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>15.5.1</b> Bayes factors in theory: Stability and accuracy</a></li>
<li class="chapter" data-level="15.5.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFvar"><i class="fa fa-check"></i><b>15.5.2</b> Bayes factors in practice: Variability with the data</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ch-bf.html"><a href="ch-bf.html#summary-13"><i class="fa fa-check"></i><b>15.6</b> Summary</a></li>
<li class="chapter" data-level="15.7" data-path="ch-bf.html"><a href="ch-bf.html#further-reading-12"><i class="fa fa-check"></i><b>15.7</b> Further reading</a></li>
<li class="chapter" data-level="15.8" data-path="ch-bf.html"><a href="ch-bf.html#exercises-2"><i class="fa fa-check"></i><b>15.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>16</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-cv.html"><a href="ch-cv.html#expected-log-predictive-density-of-a-model"><i class="fa fa-check"></i><b>16.1</b> Expected log predictive density of a model</a></li>
<li class="chapter" data-level="16.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>16.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="16.3" data-path="ch-cv.html"><a href="ch-cv.html#testing-the-n400-effect-using-cross-validation"><i class="fa fa-check"></i><b>16.3</b> Testing the N400 effect using cross-validation</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-psis-loo"><i class="fa fa-check"></i><b>16.3.1</b> Cross-validation with PSIS-LOO</a></li>
<li class="chapter" data-level="16.3.2" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-k-fold"><i class="fa fa-check"></i><b>16.3.2</b> Cross-validation with K-fold</a></li>
<li class="chapter" data-level="16.3.3" data-path="ch-cv.html"><a href="ch-cv.html#leave-one-group-out-cross-validation"><i class="fa fa-check"></i><b>16.3.3</b> Leave-one-group-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="ch-cv.html"><a href="ch-cv.html#sec-logcv"><i class="fa fa-check"></i><b>16.4</b> Comparing different likelihoods with cross-validation</a></li>
<li class="chapter" data-level="16.5" data-path="ch-cv.html"><a href="ch-cv.html#issues-with-cross-validation"><i class="fa fa-check"></i><b>16.5</b> Issues with cross-validation</a></li>
<li class="chapter" data-level="16.6" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>16.6</b> Cross-validation in Stan</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="ch-cv.html"><a href="ch-cv.html#psis-loo-cv-in-stan"><i class="fa fa-check"></i><b>16.6.1</b> PSIS-LOO-CV in Stan</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="ch-cv.html"><a href="ch-cv.html#summary-14"><i class="fa fa-check"></i><b>16.7</b> Summary</a></li>
<li class="chapter" data-level="16.8" data-path="ch-cv.html"><a href="ch-cv.html#further-reading-13"><i class="fa fa-check"></i><b>16.8</b> Further reading</a></li>
<li class="chapter" data-level="16.9" data-path="ch-cv.html"><a href="ch-cv.html#exercises-3"><i class="fa fa-check"></i><b>16.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Computational cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="17" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>17</b> Introduction to computational cognitive modeling</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-cogmod.html"><a href="ch-cogmod.html#further-reading-14"><i class="fa fa-check"></i><b>17.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>18</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-multiple-categorical-responses"><i class="fa fa-check"></i><b>18.1</b> Modeling multiple categorical responses</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mult"><i class="fa fa-check"></i><b>18.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-cat"><i class="fa fa-check"></i><b>18.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models"><i class="fa fa-check"></i><b>18.2</b> Modeling picture naming abilities in aphasia with MPT models</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="ch-MPT.html"><a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches"><i class="fa fa-check"></i><b>18.2.1</b> Calculation of the probabilities in the MPT branches</a></li>
<li class="chapter" data-level="18.2.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mpt-data"><i class="fa fa-check"></i><b>18.2.2</b> A simple MPT model</a></li>
<li class="chapter" data-level="18.2.3" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-reg"><i class="fa fa-check"></i><b>18.2.3</b> An MPT assuming by-item variability</a></li>
<li class="chapter" data-level="18.2.4" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-h"><i class="fa fa-check"></i><b>18.2.4</b> A hierarchical MPT</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="ch-MPT.html"><a href="ch-MPT.html#further-reading-15"><i class="fa fa-check"></i><b>18.3</b> Further reading</a></li>
<li class="chapter" data-level="18.4" data-path="ch-MPT.html"><a href="ch-MPT.html#exercises-4"><i class="fa fa-check"></i><b>18.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>19</b> Mixture models</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ch-mixture.html"><a href="ch-mixture.html#a-mixture-model-of-the-speed-accuracy-trade-off-the-fast-guess-model-account"><i class="fa fa-check"></i><b>19.1</b> A mixture model of the speed-accuracy trade-off: The fast-guess model account</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="ch-mixture.html"><a href="ch-mixture.html#the-global-motion-detection-task"><i class="fa fa-check"></i><b>19.1.1</b> The global motion detection task</a></li>
<li class="chapter" data-level="19.1.2" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-simplefastguess"><i class="fa fa-check"></i><b>19.1.2</b> A very simple implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.3" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-multmix"><i class="fa fa-check"></i><b>19.1.3</b> A multivariate implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.4" data-path="ch-mixture.html"><a href="ch-mixture.html#an-implementation-of-the-fast-guess-model-that-takes-instructions-into-account"><i class="fa fa-check"></i><b>19.1.4</b> An implementation of the fast-guess model that takes instructions into account</a></li>
<li class="chapter" data-level="19.1.5" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-fastguessh"><i class="fa fa-check"></i><b>19.1.5</b> A hierarchical implementation of the fast-guess model</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="ch-mixture.html"><a href="ch-mixture.html#summary-15"><i class="fa fa-check"></i><b>19.2</b> Summary</a></li>
<li class="chapter" data-level="19.3" data-path="ch-mixture.html"><a href="ch-mixture.html#further-reading-16"><i class="fa fa-check"></i><b>19.3</b> Further reading</a></li>
<li class="chapter" data-level="19.4" data-path="ch-mixture.html"><a href="ch-mixture.html#exercises-5"><i class="fa fa-check"></i><b>19.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html"><i class="fa fa-check"></i><b>20</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="20.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#modeling-a-lexical-decision-task"><i class="fa fa-check"></i><b>20.1</b> Modeling a lexical decision task</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-acccoding"><i class="fa fa-check"></i><b>20.1.1</b> Modeling the lexical decision task with the log-normal race model</a></li>
<li class="chapter" data-level="20.1.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-genaccum"><i class="fa fa-check"></i><b>20.1.2</b> A generative model for a race between accumulators</a></li>
<li class="chapter" data-level="20.1.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#fitting-the-log-normal-race-model"><i class="fa fa-check"></i><b>20.1.3</b> Fitting the log-normal race model</a></li>
<li class="chapter" data-level="20.1.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-lognormalh"><i class="fa fa-check"></i><b>20.1.4</b> A hierarchical implementation of the log-normal race model</a></li>
<li class="chapter" data-level="20.1.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-contaminant"><i class="fa fa-check"></i><b>20.1.5</b> Dealing with contaminant responses</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#posterior-predictive-check-with-the-quantile-probability-plots"><i class="fa fa-check"></i><b>20.2</b> Posterior predictive check with the quantile probability plots</a></li>
<li class="chapter" data-level="20.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#summary-16"><i class="fa fa-check"></i><b>20.3</b> Summary</a></li>
<li class="chapter" data-level="20.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#further-reading-17"><i class="fa fa-check"></i><b>20.4</b> Further reading</a></li>
<li class="chapter" data-level="20.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#exercises-6"><i class="fa fa-check"></i><b>20.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-MPT" class="section level1 hasAnchor" number="18">
<h1><span class="header-section-number">Chapter 18</span> Multinomial processing trees<a href="ch-MPT.html#ch-MPT" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, we introduce a widely-used cognitive model that can be implemented in Stan, the multinomial processing tree. This model is useful in situations where the behavioral response from the subject is one of several possible categorical outcomes. As an example, we will look into a word production task, where we ask subjects with aphasia <span class="citation">(a language impairment mostly due to a cerebrovascular accident or head trauma, <a href="#ref-damasio1992aphasia" role="doc-biblioref">Damasio 1992</a>)</span>, to name the object shown in a picture, e.g., a picture of a cat. A subject could produce the correct name (“cat”), a semantically and phonologically related but incorrect name (“rat”), a semantically unrelated but phonologically related word (“hat”), or a non-word (“cag”). The researcher may have a theory about how each possible outcome ends up being probabilistically produced. Such a theoretical process model can be expressed as a multinomial processing tree. Before we dive into multinomial processing trees, we discuss the distributions that generalize the binomial and Bernoulli distribution for modeling more than two possible outcomes.</p>
<div id="modeling-multiple-categorical-responses" class="section level2 hasAnchor" number="18.1">
<h2><span class="header-section-number">18.1</span> Modeling multiple categorical responses<a href="ch-MPT.html#modeling-multiple-categorical-responses" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One way to model categorical responses is using multinomial or categorical distributions.
The categorical responses could be “yes” or “no”; “blue”, “red” or “yellow”; “true”, “false”, or “I don’t know”; or more complicated categories, but crucially the response of each observation can be coded as only belonging to only one category. The multinomial and the categorical distribution represent two ways of characterizing the underlying generative process for such data.</p>
<p>The <em>multinomial distribution</em> is the generalization of the binomial distribution for more than two possible outcomes. Recall that the binomial works like this: in order to randomly generate the number of successes in observation consisting of <span class="math inline">\(10\)</span> trials, with the probability of success <span class="math inline">\(0.5\)</span>, one can type:</p>
<div class="sourceCode" id="cb986"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb986-1"><a href="ch-MPT.html#cb986-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>It is possible to repeatedly generate multiple observations as follows. Suppose five simulated observations are needed, each with <span class="math inline">\(10\)</span> trials:</p>
<div class="sourceCode" id="cb988"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb988-1"><a href="ch-MPT.html#cb988-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 6 5 7 7 2</code></pre>
<p>Now, suppose that there are N=3 possible answers to a question (yes, no don’t know), and suppose that the probabilities of producing each answer are:</p>
<ul>
<li><span class="math inline">\(P(\)</span>yes<span class="math inline">\()=0.1\)</span></li>
<li><span class="math inline">\(P(\)</span>no<span class="math inline">\()=0.1\)</span></li>
<li><span class="math inline">\(P(\)</span>don’t know<span class="math inline">\()=0.8\)</span></li>
</ul>
<p>The probabilities must sum to <span class="math inline">\(1\)</span>, because those are the only three possible outcomes. Given such a situation, it is possible to simulate a single experiment with <span class="math inline">\(10\)</span> trials, where each of the three possibilities appears a certain number of times. We do this with <code>rmnom</code> from the <code>extraDistr</code> package (one could have used <code>rmultinom()</code> in R equally well, but the output would look a bit different):</p>
<div class="sourceCode" id="cb990"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb990-1"><a href="ch-MPT.html#cb990-1" aria-hidden="true" tabindex="-1"></a>(random_sample <span class="ot">&lt;-</span> <span class="fu">rmnom</span>(<span class="dv">1</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.8</span>)))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    2    8</code></pre>
<p>The above call returns the result of the random sample: <span class="math inline">\(0\)</span> cases of the first answer type, <span class="math inline">\(2\)</span> cases of the second; and <span class="math inline">\(8\)</span> cases of the third.</p>
<p>Analogously to the binomial function shown above, five observations can be simulated, each having 10 trials:</p>
<div class="sourceCode" id="cb992"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb992-1"><a href="ch-MPT.html#cb992-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmnom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    2    7
## [2,]    3    0    7
## [3,]    1    2    7
## [4,]    1    1    8
## [5,]    3    1    6</code></pre>
<p>The <em>categorical distribution</em> is the generalization of the Bernoulli distribution for more than two possible outcomes, and it is the special case of the multinomial distribution when we have only one trial. Recall that the Bernoulli distribution can be used as follows. If we carry out a coin toss (each coin toss counts as a single trial), we will either get a heads or a tails:</p>
<div class="sourceCode" id="cb994"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb994-1"><a href="ch-MPT.html#cb994-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbern</span>(<span class="dv">5</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 1 1 0 1 0</code></pre>
<div class="sourceCode" id="cb996"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb996-1"><a href="ch-MPT.html#cb996-1" aria-hidden="true" tabindex="-1"></a><span class="do">## equivalent rbinom command:</span></span>
<span id="cb996-2"><a href="ch-MPT.html#cb996-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0 0 1 1 1</code></pre>
<p>Thus, what the Bernoulli is to the Binomial, the Categorical is to the Multinomial. For example, one can simulate five observations, each of which will give one of the three responses with the given probabilities. We do this with <code>rcat</code> from the <code>extraDistr</code> package.</p>
<div class="sourceCode" id="cb998"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb998-1"><a href="ch-MPT.html#cb998-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rcat</span>(<span class="dv">5</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.8</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>, <span class="st">&quot;dontknow&quot;</span>))</span></code></pre></div>
<pre><code>## [1] dontknow yes      dontknow dontknow dontknow
## Levels: yes no dontknow</code></pre>
<p>The above is analogous to using the multinomial with <code>size = 1</code> (a single trial in each experiment). In the output below, the <code>rmnom</code> function shows which of the three categories is produced.</p>
<div class="sourceCode" id="cb1000"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1000-1"><a href="ch-MPT.html#cb1000-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmnom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.8</span>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    0    1
## [2,]    0    1    0
## [3,]    1    0    0
## [4,]    0    0    1
## [5,]    0    0    1</code></pre>
<p>With these distributions as background, consider now a simulated situation where multiple responses are possible.</p>
<div id="sec-mult" class="section level3 hasAnchor" number="18.1.1">
<h3><span class="header-section-number">18.1.1</span> A model for multiple responses using the multinomial likelihood<a href="ch-MPT.html#sec-mult" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Impaired picture naming (anomia) is common in most cases of aphasia. It is assessed as part of most comprehensive aphasia test batteries, since picture naming accuracy is a relatively easily obtained and is a reliable test score; in addition, the types of errors that are committed can provide useful information for diagnosis.</p>
<p>In this simulated experiment, the responses are categorized as shown in Table <a href="ch-MPT.html#tab:responses">18.1</a>.</p>
<table>
<caption><span id="tab:responses">TABLE 18.1: </span> Categorization of responses for the simulated experiment.</caption>
<colgroup>
<col width="15%" />
<col width="77%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Category</th>
<th align="left">Description</th>
<th align="left">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Correct</td>
<td align="left">The response matches the target.</td>
<td align="left">cat</td>
</tr>
<tr class="even">
<td align="left">Neologism</td>
<td align="left">The response is not a word, but it has a phonological relation to the target.</td>
<td align="left">cag</td>
</tr>
<tr class="odd">
<td align="left">Formal</td>
<td align="left">The response is a word with only a phonological relation to the target.</td>
<td align="left">hat</td>
</tr>
<tr class="even">
<td align="left">Mixed</td>
<td align="left">The response is a word with both a semantic and phonological relation the target.</td>
<td align="left">rat</td>
</tr>
<tr class="odd">
<td align="left">NR</td>
<td align="left">All other responses, including omissions, descriptions, non-nouns, etc.</td>
<td align="left">–</td>
</tr>
</tbody>
</table>
<p>First, generate data assuming a multinomial distribution. The outcomes will be determined by a vector <span class="math inline">\(\boldsymbol{\theta}\)</span> (called <code>true_theta</code> below in the R code) that indicates the probability of each outcome:</p>
<div class="sourceCode" id="cb1002"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1002-1"><a href="ch-MPT.html#cb1002-1" aria-hidden="true" tabindex="-1"></a>(true_theta <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta_NR =</span> .<span class="dv">2</span>, </span>
<span id="cb1002-2"><a href="ch-MPT.html#cb1002-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">theta_Neologism =</span> .<span class="dv">1</span>,</span>
<span id="cb1002-3"><a href="ch-MPT.html#cb1002-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">theta_Formal =</span> .<span class="dv">2</span>,</span>
<span id="cb1002-4"><a href="ch-MPT.html#cb1002-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">theta_Mixed =</span> .<span class="dv">08</span>,</span>
<span id="cb1002-5"><a href="ch-MPT.html#cb1002-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">theta_Correct =</span>  <span class="dv">1</span> <span class="sc">-</span></span>
<span id="cb1002-6"><a href="ch-MPT.html#cb1002-6" aria-hidden="true" tabindex="-1"></a>  (theta_NR <span class="sc">+</span> theta_Neologism <span class="sc">+</span> theta_Formal <span class="sc">+</span> theta_Mixed)))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 5
##   theta_NR theta_Neologism theta_Formal theta_Mixed theta_Correct
##      &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;
## 1      0.2             0.1          0.2        0.08          0.42</code></pre>
<div class="sourceCode" id="cb1004"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1004-1"><a href="ch-MPT.html#cb1004-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The probabilities must sum to 1:</span></span>
<span id="cb1004-2"><a href="ch-MPT.html#cb1004-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(true_theta)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Given this vector of probabilities <span class="math inline">\(\boldsymbol{\theta}\)</span>, generate values assuming a multinomial distribution of responses in 100 trials:</p>
<div class="sourceCode" id="cb1006"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1006-1"><a href="ch-MPT.html#cb1006-1" aria-hidden="true" tabindex="-1"></a>N_trials <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1006-2"><a href="ch-MPT.html#cb1006-2" aria-hidden="true" tabindex="-1"></a>(ans_mn <span class="ot">&lt;-</span> <span class="fu">rmultinom</span>(<span class="dv">1</span>, N_trials, true_theta))</span></code></pre></div>
<pre><code>##                 [,1]
## theta_NR          23
## theta_Neologism    7
## theta_Formal      18
## theta_Mixed        6
## theta_Correct     46</code></pre>
<p>Now, we’ll try to recover the probability of each answer with a model with the following likelihood:</p>
<p><span class="math display">\[\begin{equation}
ans \sim \mathit{Multinomial}(\boldsymbol{\theta})
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\theta} = \{\theta_{nr}, \theta_{neol.}, \theta_{formal}, \theta_{mix}, \theta_{corr}\}\)</span>.</p>
<p>A common prior for multinomial likelihood is the Dirichlet distribution, which extends the Beta distribution to cases where more than two categories are available.</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\theta} \sim \mathit{Dirichlet}(\boldsymbol{\alpha})
\end{equation}\]</span></p>
<p>The Dirichlet distribution has a parameter <span class="math inline">\(\alpha\)</span>, called concentration parameter, and it is a vector with the same length as <span class="math inline">\(\boldsymbol{\theta}\)</span>. If we set <span class="math inline">\(\boldsymbol{\alpha} = \{2,2,2,2,2\}\)</span>, this is analogous to <span class="math inline">\(\sim \mathit{Beta}(2,2)\)</span>, that is, the intuition behind this concentration parameter is that the prior probability distribution of the vector <span class="math inline">\(\boldsymbol{\theta}\)</span> corresponds to have seen two outcomes of each category in the past.</p>
<p>A Stan model assuming a multinomial likelihood and Dirichlet prior is shown below. Since the elements of <span class="math inline">\(\boldsymbol{\theta}\)</span> should sum to one we declare this vector, <code>theta</code>, as a <code>simplex</code>. A simplex guarantees that its elements sum to one and also constraints them to have non-negative values. In order to generate the vector <span class="math inline">\(\boldsymbol{\alpha}\)</span> that contains five times the value two, we use <code>rep_vector(2, 5)</code> (which is similar to <code>rep(2, 5)</code> in R).</p>
<div class="sourceCode" id="cb1008"><pre class="sourceCode stan fold-show"><code class="sourceCode stan"><span id="cb1008-1"><a href="ch-MPT.html#cb1008-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1008-2"><a href="ch-MPT.html#cb1008-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>&gt; N_trials;</span>
<span id="cb1008-3"><a href="ch-MPT.html#cb1008-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>,<span class="kw">upper</span> = N_trials&gt; ans[<span class="dv">5</span>];</span>
<span id="cb1008-4"><a href="ch-MPT.html#cb1008-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1008-5"><a href="ch-MPT.html#cb1008-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1008-6"><a href="ch-MPT.html#cb1008-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[<span class="dv">5</span>] theta;</span>
<span id="cb1008-7"><a href="ch-MPT.html#cb1008-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1008-8"><a href="ch-MPT.html#cb1008-8" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1008-9"><a href="ch-MPT.html#cb1008-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> dirichlet_lpdf(theta | rep_vector(<span class="dv">2</span>, <span class="dv">5</span>));</span>
<span id="cb1008-10"><a href="ch-MPT.html#cb1008-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> multinomial_lpmf(ans | theta);</span>
<span id="cb1008-11"><a href="ch-MPT.html#cb1008-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1008-12"><a href="ch-MPT.html#cb1008-12" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb1008-13"><a href="ch-MPT.html#cb1008-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> pred_ans[<span class="dv">5</span>] = multinomial_rng(theta, <span class="dv">5</span>);</span>
<span id="cb1008-14"><a href="ch-MPT.html#cb1008-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Fit the model:</p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1009-1"><a href="ch-MPT.html#cb1009-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list:</span></span>
<span id="cb1009-2"><a href="ch-MPT.html#cb1009-2" aria-hidden="true" tabindex="-1"></a><span class="co"># c(ans_mn) makes a vector out of the matrix ans_mn</span></span>
<span id="cb1009-3"><a href="ch-MPT.html#cb1009-3" aria-hidden="true" tabindex="-1"></a>data_mn <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">N_trials =</span> N_trials,</span>
<span id="cb1009-4"><a href="ch-MPT.html#cb1009-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">ans =</span> <span class="fu">c</span>(ans_mn))</span></code></pre></div>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1010-1"><a href="ch-MPT.html#cb1010-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data_mn)</span></code></pre></div>
<pre><code>## List of 2
##  $ N_trials: num 100
##  $ ans     : int [1:5] 23 7 18 6 46</code></pre>
<div class="sourceCode" id="cb1012"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1012-1"><a href="ch-MPT.html#cb1012-1" aria-hidden="true" tabindex="-1"></a>multinom <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1012-2"><a href="ch-MPT.html#cb1012-2" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;multinom.stan&quot;</span>,</span>
<span id="cb1012-3"><a href="ch-MPT.html#cb1012-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb1012-4"><a href="ch-MPT.html#cb1012-4" aria-hidden="true" tabindex="-1"></a>fit_mn <span class="ot">&lt;-</span> <span class="fu">stan</span>(multinom, <span class="at">data =</span> data_mn)</span></code></pre></div>
<p>Print the posteriors:</p>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1013-1"><a href="ch-MPT.html#cb1013-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_mn, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>))</span></code></pre></div>
<pre><code>##          mean 2.5% 97.5% n_eff Rhat
## theta[1] 0.23 0.16  0.31  3909    1
## theta[2] 0.08 0.04  0.14  4612    1
## theta[3] 0.18 0.11  0.26  4198    1
## theta[4] 0.07 0.03  0.13  4639    1
## theta[5] 0.44 0.35  0.53  4818    1</code></pre>
<p>Next, we use <code>mcmc_recover_hist</code> in the code below to confirm that the posterior distributions of the elements of <span class="math inline">\(\boldsymbol{\theta}\)</span> are close to the true values that were set up when simulating the data. See Figure <a href="ch-MPT.html#fig:multin-posterior">18.1</a>.</p>

<div class="sourceCode" id="cb1015"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1015-1"><a href="ch-MPT.html#cb1015-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(fit_mn) <span class="sc">%&gt;%</span></span>
<span id="cb1015-2"><a href="ch-MPT.html#cb1015-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">&quot;theta&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1015-3"><a href="ch-MPT.html#cb1015-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mcmc_recover_hist</span>(<span class="at">true =</span> <span class="fu">unlist</span>(true_theta)) <span class="sc">+</span></span>
<span id="cb1015-4"><a href="ch-MPT.html#cb1015-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:multin-posterior"></span>
<img src="bookdown_files/figure-html/multin-posterior-1.svg" alt="Posterior distributions and true means of theta for the multinomial model defined in multinom.stan." width="672" />
<p class="caption">
FIGURE 18.1: Posterior distributions and true means of theta for the multinomial model defined in <code>multinom.stan</code>.
</p>
</div>
<p>We evaluate here whether our model is able to “recover” the true value of its parameters. By “recover”, we mean that the true values are somewhere inside the posterior distribution of the model.</p>
<p>The frequentist properties of Bayesian models guarantee that if we simulate data several times, 95% of the true values should be inside of the 95% CrI intervals generated by a “well-calibrated” model. Furthermore, if the true values of some parameters are consistently well above or below their posterior distribution, it may mean that there is some problem with the model specification. We follow <span class="citation">Cook, Gelman, and Rubin (<a href="#ref-Cooketal2006" role="doc-biblioref">2006</a>)</span> here, and for now we are going to verify that our model is roughly correct. A more principled (and computationally demanding) approach uses simulation based calibration (SBC) introduced in section <a href="ch-custom.html#sec-validSBC">12.2</a> of chapter <a href="ch-custom.html#ch-custom">12</a> <span class="citation">(and see also <a href="#ref-talts2018validating" role="doc-biblioref">Talts et al. 2018</a>; <a href="#ref-schad2020toward" role="doc-biblioref">Daniel J. Schad, Betancourt, and Vasishth 2020</a>)</span>.</p>
</div>
<div id="sec-cat" class="section level3 hasAnchor" number="18.1.2">
<h3><span class="header-section-number">18.1.2</span> A model for multiple responses using the categorical distribution<a href="ch-MPT.html#sec-cat" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using the same information as above, we can model each response one at a time, instead of aggregating them. Using the categorical distributions gives us more flexibility to define what happens at every trial. However, we are not using the additional flexibility for now, and hence the next model and the previous one are equivalent.</p>
<div class="sourceCode" id="cb1016"><pre class="sourceCode stan fold-show"><code class="sourceCode stan"><span id="cb1016-1"><a href="ch-MPT.html#cb1016-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1016-2"><a href="ch-MPT.html#cb1016-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>&gt; N_obs;</span>
<span id="cb1016-3"><a href="ch-MPT.html#cb1016-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>, <span class="kw">upper</span> = <span class="dv">5</span>&gt; w_ans[N_obs];</span>
<span id="cb1016-4"><a href="ch-MPT.html#cb1016-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1016-5"><a href="ch-MPT.html#cb1016-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1016-6"><a href="ch-MPT.html#cb1016-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[<span class="dv">5</span>] theta;</span>
<span id="cb1016-7"><a href="ch-MPT.html#cb1016-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1016-8"><a href="ch-MPT.html#cb1016-8" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1016-9"><a href="ch-MPT.html#cb1016-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> dirichlet_lpdf(theta | rep_vector(<span class="dv">2</span>, <span class="dv">5</span>));</span>
<span id="cb1016-10"><a href="ch-MPT.html#cb1016-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1016-11"><a href="ch-MPT.html#cb1016-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> categorical_lpmf(w_ans[n] | theta);</span>
<span id="cb1016-12"><a href="ch-MPT.html#cb1016-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1016-13"><a href="ch-MPT.html#cb1016-13" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb1016-14"><a href="ch-MPT.html#cb1016-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> pred_w_ans[N_obs];</span>
<span id="cb1016-15"><a href="ch-MPT.html#cb1016-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1016-16"><a href="ch-MPT.html#cb1016-16" aria-hidden="true" tabindex="-1"></a>    pred_w_ans[n] = categorical_rng(theta);</span>
<span id="cb1016-17"><a href="ch-MPT.html#cb1016-17" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Given the same set of probabilities <span class="math inline">\(\boldsymbol{\theta}\)</span> as above, generate 100 individual observations:</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1017-1"><a href="ch-MPT.html#cb1017-1" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="dv">100</span> </span>
<span id="cb1017-2"><a href="ch-MPT.html#cb1017-2" aria-hidden="true" tabindex="-1"></a>ans_cat <span class="ot">&lt;-</span> <span class="fu">rcat</span>(N_obs, <span class="at">prob =</span> <span class="fu">as.matrix</span>(true_theta))</span></code></pre></div>
<p>The above output is how Stan expects to see the data. The data fed into the Stan model is defined as a list as usual:</p>
<div class="sourceCode" id="cb1018"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1018-1"><a href="ch-MPT.html#cb1018-1" aria-hidden="true" tabindex="-1"></a>data_cat <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">N_obs =</span> N_obs,</span>
<span id="cb1018-2"><a href="ch-MPT.html#cb1018-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">w_ans =</span> ans_cat)</span>
<span id="cb1018-3"><a href="ch-MPT.html#cb1018-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data_cat)</span></code></pre></div>
<pre><code>## List of 2
##  $ N_obs: num 100
##  $ w_ans: num [1:100] 1 3 3 3 1 1 2 3 2 5 ...</code></pre>
<p>Fitting the Stan model (<code>categorical.stan</code>) should yield approximately the same <span class="math inline">\(\boldsymbol{\theta}\)</span> as with the multinomial likelihood defined in the model <code>multinom.stan</code>.</p>
<!-- See Figure \@ref(fig:cat-posterior). -->
<div class="sourceCode" id="cb1020"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1020-1"><a href="ch-MPT.html#cb1020-1" aria-hidden="true" tabindex="-1"></a>categorical <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1020-2"><a href="ch-MPT.html#cb1020-2" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;categorical.stan&quot;</span>,</span>
<span id="cb1020-3"><a href="ch-MPT.html#cb1020-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb1020-4"><a href="ch-MPT.html#cb1020-4" aria-hidden="true" tabindex="-1"></a>fit_cat <span class="ot">&lt;-</span> <span class="fu">stan</span>(categorical, <span class="at">data =</span> data_cat)  </span></code></pre></div>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1021-1"><a href="ch-MPT.html#cb1021-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_cat, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>))</span></code></pre></div>
<pre><code>##          mean 2.5% 97.5% n_eff Rhat
## theta[1] 0.19 0.13  0.27  4177    1
## theta[2] 0.08 0.04  0.14  4857    1
## theta[3] 0.27 0.19  0.36  4853    1
## theta[4] 0.06 0.02  0.10  4428    1
## theta[5] 0.40 0.31  0.49  4410    1</code></pre>
<!-- Again we confirm that the posterior distributions of the elements of $\boldsymbol{\theta}$ are close to their true values; see Figure \@ref(fig:cat-posterior). -->
<!-- ```{r cat-posterior, message = FALSE, tidy = FALSE, fig.cap = "Posterior distributions and true means of theta for the categorical model categorical.stan.", warning = FALSE} -->
<!-- as.data.frame(fit_cat) %>% -->
<!--   select(starts_with("theta")) %>% -->
<!--   mcmc_recover_hist(true = unlist(true_theta)) + -->
<!--   coord_cartesian(xlim = c(0, 1)) -->
<!-- ``` -->
<p>The above models estimate the posterior distribution for the probability for each possible response. If we had some experimental manipulation, we could even fit regressions to these parameters. This is called a multinomial logistic regression or categorical regression, see further reading for some examples.</p>
</div>
</div>
<div id="modeling-picture-naming-abilities-in-aphasia-with-mpt-models" class="section level2 hasAnchor" number="18.2">
<h2><span class="header-section-number">18.2</span> Modeling picture naming abilities in aphasia with MPT models<a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Multinomial processing tree (MPT) modeling is a method that estimates latent variables that have a psychological interpretation given categorical data <span class="citation">(a review is provided in <a href="#ref-BatchelderRiefer1999" role="doc-biblioref">Batchelder and Riefer 1999</a>)</span>. In other words, an MPT model is just one way to model categorical responses following a multinomial or categorical distribution. MPT models assume that the observed response categories result from a sequences of underlying cognitive events which are represented as a binary branching tree. Each binary branching is associated with a parameter that represents the probability of going down either branch. Every successive node is assumed to be independent of the preceding node, allowing us to use the product rule from probability theory to compute the probability of going down a particular path. The leaves of the binary branching tree the observed response in the data. The goal is to derive posterior distributions of the latent probability parameters specified for the binary branching in the model.</p>
<p><span class="citation">Walker, Hickok, and Fridriksson (<a href="#ref-WalkerEtAl2018" role="doc-biblioref">2018</a>)</span> created an MPT model that specifies a set of possible internal errors that lead to the various possible response types during a picture naming trial for aphasic patients. Here we’ll explore a simplification of the original model.</p>
<p>The model assumes that when an attempt is made to produce a word, errors in production can arise at the whole word level (lexical level) or the segmental level (phonological level). Semantic errors are assumed to arise from the lexical substitutions, and neologism errors from phonological substitutions. Real word responses that are phonologically related to the correct target word can arise from substitutions at the lexical or phonological level.</p>
<p>The task for the subject is to view a picture and name the object represented in the picture. When an attempt is made to retrieve the word from memory, the following possible steps can unfold (this is a simplified version of the original model):</p>
<ul>
<li>Either the subject will make some lexical selection, or fail to make a lexical selection, returning a non-response (NR). The probability of making some lexical selection is <span class="math inline">\(a\)</span>, so the probability of a non-response is <span class="math inline">\(1-a\)</span>, as these are only two possibilities at this initial stage of the binary branching tree. Example: the subject sees the picture of a cat, and either produces the response “I don’t know”, or starts the process of producing a word.</li>
<li>If a lexical selection is made, the target word is selected with probability <span class="math inline">\(t\)</span>, or some other word is chosen with probability <span class="math inline">\(1-t\)</span>.</li>
<li>Once a word is selected, either its phonological representation is selected with probability <span class="math inline">\(f\)</span>, or some other (incorrect) phonological representation is selected with probability <span class="math inline">\(1-f\)</span>.<br />
</li>
<li>Once a word is selected, there can be a phonological change that leads to a real, formally related word with probability <span class="math inline">\(c\)</span>, or a neologism with probability <span class="math inline">\(1-c\)</span>. Example: the subjects produces either a formally related word “hat”, or a neologism like “cag”.</li>
</ul>
<p>The end-result of walking down this tree is that the subject either produces a non-response (“I don’t know” or silence), a correct response, a related word, a mixed word, or a neologism. There is more than one way to produce a neologism or a related word, and the posterior probabilities of the various paths will determine the probability of each possible path.</p>

<div class="figure"><span style="display:block;" id="fig:MPT-tikz"></span>
<img src="bookdown_files/figure-html/MPT-tikz-1.svg" alt="Representation of a simplification of the MPT used in Walker, Hickok, and Fridriksson (2018)." width="672" />
<p class="caption">
FIGURE 18.2: Representation of a simplification of the MPT used in <span class="citation">Walker, Hickok, and Fridriksson (<a href="#ref-WalkerEtAl2018" role="doc-biblioref">2018</a>)</span>.
</p>
</div>
<table>
<caption><span id="tab:MPT-params">TABLE 18.2: </span> Psychological interpretation of the parameters of the MPT model.</caption>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Param.</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a</td>
<td align="left">Probability of initiating an attempt</td>
</tr>
<tr class="even">
<td align="left">t</td>
<td align="left">Probability of selecting a target word over competitors</td>
</tr>
<tr class="odd">
<td align="left">f</td>
<td align="left">Probability of retrieving correct phonemes</td>
</tr>
<tr class="even">
<td align="left">c</td>
<td align="left">Probability of a phoneme change in the target word creating a real word</td>
</tr>
</tbody>
</table>
<div id="calculation-of-the-probabilities-in-the-mpt-branches" class="section level3 hasAnchor" number="18.2.1">
<h3><span class="header-section-number">18.2.1</span> Calculation of the probabilities in the MPT branches<a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>By navigating through the branches of the MPT (Figure <a href="ch-MPT.html#fig:MPT-tikz">18.2</a>), we can calculate the probabilities of the five responses (the categorical outcomes), based on the four underlying parameters assumed in the MPT:</p>
<ul>
<li><span class="math inline">\(P(\mathit{NR}| a,t,f,c)= 1-a\)</span></li>
<li><span class="math inline">\(P(\mathit{Neologism}| a,t,f,c)= a \cdot (1-t) \cdot (1-f) \cdot (1-c) + a \cdot t \cdot (1-f) \cdot (1-c)\)</span></li>
<li><span class="math inline">\(P(\mathit{Formal}| a,t,f,c)= a \cdot (1-t) \cdot (1-f) \cdot c + a \cdot t \cdot (1-f) \cdot c\)</span></li>
<li><span class="math inline">\(P(\mathit{Mixed}| a,t,f,c)= a \cdot (1-t) \cdot f\)</span></li>
<li><span class="math inline">\(P(\mathit{Correct}| a,t,f,c)= a \cdot t \cdot f\)</span></li>
</ul>
<p>Given that</p>
<p><span class="math display">\[\begin{multline}
P(\mathit{NR}| a,t,f,c) + P(\mathit{Neologism}| a,t,f,c) + P(\mathit{Formal}| a,t,f,c) + \\
P(\mathit{Mixed}| a,t,f,c) + P(\mathit{Correct}| a,t,f,c) = 1
\end{multline}\]</span></p>
<p>there is no need to characterize every outcome: we can always calculate any one of the remaining responses as one minus the other responses.</p>
</div>
<div id="sec-mpt-data" class="section level3 hasAnchor" number="18.2.2">
<h3><span class="header-section-number">18.2.2</span> A simple MPT model<a href="ch-MPT.html#sec-mpt-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!-- ### Generate simulated data  -->
<p>First, simulate 200 trials assuming no variability between items and subjects. It is convenient to define functions to compute each outcome’s probability, based on the previous MPT. One needs to assign “true values” to the underlying parameters of the MPT, these values are for illustration. Ideally, one should simulate data using realistic values for the main parameters based on the literature.</p>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb1023"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1023-1"><a href="ch-MPT.html#cb1023-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilities of different answers</span></span>
<span id="cb1023-2"><a href="ch-MPT.html#cb1023-2" aria-hidden="true" tabindex="-1"></a>Pr_NR <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1023-3"><a href="ch-MPT.html#cb1023-3" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span> <span class="sc">-</span> a</span>
<span id="cb1023-4"><a href="ch-MPT.html#cb1023-4" aria-hidden="true" tabindex="-1"></a>Pr_Neologism <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1023-5"><a href="ch-MPT.html#cb1023-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> c) <span class="sc">+</span> a <span class="sc">*</span> t <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> c)</span>
<span id="cb1023-6"><a href="ch-MPT.html#cb1023-6" aria-hidden="true" tabindex="-1"></a>Pr_Formal <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1023-7"><a href="ch-MPT.html#cb1023-7" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> c <span class="sc">+</span>  a <span class="sc">*</span> t <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> c</span>
<span id="cb1023-8"><a href="ch-MPT.html#cb1023-8" aria-hidden="true" tabindex="-1"></a>Pr_Mixed <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1023-9"><a href="ch-MPT.html#cb1023-9" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> f</span>
<span id="cb1023-10"><a href="ch-MPT.html#cb1023-10" aria-hidden="true" tabindex="-1"></a>Pr_Correct <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1023-11"><a href="ch-MPT.html#cb1023-11" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> t <span class="sc">*</span> f</span>
<span id="cb1023-12"><a href="ch-MPT.html#cb1023-12" aria-hidden="true" tabindex="-1"></a><span class="co"># true underlying values for simulated data</span></span>
<span id="cb1023-13"><a href="ch-MPT.html#cb1023-13" aria-hidden="true" tabindex="-1"></a>a_true <span class="ot">&lt;-</span> .<span class="dv">75</span></span>
<span id="cb1023-14"><a href="ch-MPT.html#cb1023-14" aria-hidden="true" tabindex="-1"></a>t_true <span class="ot">&lt;-</span> .<span class="dv">9</span></span>
<span id="cb1023-15"><a href="ch-MPT.html#cb1023-15" aria-hidden="true" tabindex="-1"></a>f_true <span class="ot">&lt;-</span> .<span class="dv">8</span></span>
<span id="cb1023-16"><a href="ch-MPT.html#cb1023-16" aria-hidden="true" tabindex="-1"></a>c_true <span class="ot">&lt;-</span> .<span class="dv">1</span></span>
<span id="cb1023-17"><a href="ch-MPT.html#cb1023-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of the different answers:</span></span>
<span id="cb1023-18"><a href="ch-MPT.html#cb1023-18" aria-hidden="true" tabindex="-1"></a>Theta <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">NR =</span> <span class="fu">Pr_NR</span>(a_true, t_true, f_true, c_true),</span>
<span id="cb1023-19"><a href="ch-MPT.html#cb1023-19" aria-hidden="true" tabindex="-1"></a>                <span class="at">Neologism =</span> <span class="fu">Pr_Neologism</span>(a_true, t_true, f_true, c_true),</span>
<span id="cb1023-20"><a href="ch-MPT.html#cb1023-20" aria-hidden="true" tabindex="-1"></a>                <span class="at">Formal =</span> <span class="fu">Pr_Formal</span>(a_true, t_true, f_true, c_true),</span>
<span id="cb1023-21"><a href="ch-MPT.html#cb1023-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">Mixed =</span> <span class="fu">Pr_Mixed</span>(a_true, t_true, f_true, c_true),</span>
<span id="cb1023-22"><a href="ch-MPT.html#cb1023-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">Correct =</span> <span class="fu">Pr_Correct</span>(a_true, t_true, f_true, c_true))</span>
<span id="cb1023-23"><a href="ch-MPT.html#cb1023-23" aria-hidden="true" tabindex="-1"></a>N_trials <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb1023-24"><a href="ch-MPT.html#cb1023-24" aria-hidden="true" tabindex="-1"></a>(ans <span class="ot">&lt;-</span> <span class="fu">rmultinom</span>(<span class="dv">1</span>, N_trials, <span class="fu">c</span>(Theta)))</span></code></pre></div>
<pre><code>##           [,1]
## NR          49
## Neologism   26
## Formal       5
## Mixed       17
## Correct    103</code></pre>
<!-- ### A simple MPT model in Stan {#sec-MPT-s} -->
<p>The above data can be modeled in Stan as discussed below (see <code>mpt_mnm.stan</code>). The probabilities of the different categories go into the <code>transformed parameters</code> section because they are derived from the probability parameters in the model. The data are modeled as coming from a multinomial likelihood. If priors are not specified, then a Beta distribution with <span class="math inline">\(a=1\)</span> and <span class="math inline">\(b=1\)</span> (a Uniform(0,1) distribution) is assumed for the parameters <span class="math inline">\(a\)</span>, <span class="math inline">\(t\)</span>, <span class="math inline">\(f\)</span>, and <span class="math inline">\(c\)</span>. Unlike <span class="math inline">\(\boldsymbol{\theta}\)</span>, the values of these parameters are independent of each other and they do not sum to one. For this reason, we should not use a Dirichlet prior here.</p>
<p>We define the following model:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\theta_{nr} &amp;= 1-a \\
\theta_{neol.} &amp;= a \cdot (1-t) \cdot (1-f) \cdot (1-c) +  a \cdot t \cdot (1-f) \cdot (1-c)\\
\theta_{formal} &amp;= a \cdot (1-t) \cdot (1-f) \cdot c +  a \cdot t \cdot (1-f) \cdot c\\
\theta_{mix} &amp;= a \cdot (1-t) \cdot f\\
\theta_{corr} &amp;= a \cdot t \cdot f\\
\boldsymbol{\theta} &amp;= \{\theta_{nr}, \theta_{neol.}, \theta_{formal}, \theta_{mix}, \theta_{corr}\}\\
ans &amp;\sim \mathit{Multinomial}(\theta)\\
a,t,f,c &amp;\sim \mathit{Beta}(2, 2)
\end{aligned}
\end{equation}\]</span></p>
<p>This translates to the following code:</p>
<div class="sourceCode" id="cb1025"><pre class="sourceCode stan fold-show"><code class="sourceCode stan"><span id="cb1025-1"><a href="ch-MPT.html#cb1025-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> { </span>
<span id="cb1025-2"><a href="ch-MPT.html#cb1025-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>&gt; N_trials;</span>
<span id="cb1025-3"><a href="ch-MPT.html#cb1025-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = N_trials&gt; ans[<span class="dv">5</span>];</span>
<span id="cb1025-4"><a href="ch-MPT.html#cb1025-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1025-5"><a href="ch-MPT.html#cb1025-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1025-6"><a href="ch-MPT.html#cb1025-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; a;</span>
<span id="cb1025-7"><a href="ch-MPT.html#cb1025-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; t;</span>
<span id="cb1025-8"><a href="ch-MPT.html#cb1025-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; f;</span>
<span id="cb1025-9"><a href="ch-MPT.html#cb1025-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; c;</span>
<span id="cb1025-10"><a href="ch-MPT.html#cb1025-10" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb1025-11"><a href="ch-MPT.html#cb1025-11" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb1025-12"><a href="ch-MPT.html#cb1025-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[<span class="dv">5</span>] theta;</span>
<span id="cb1025-13"><a href="ch-MPT.html#cb1025-13" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">1</span>] = <span class="dv">1</span> - a; <span class="co">//Pr_NR</span></span>
<span id="cb1025-14"><a href="ch-MPT.html#cb1025-14" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">2</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c) + a * t * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c); <span class="co">//Pr_Neologism</span></span>
<span id="cb1025-15"><a href="ch-MPT.html#cb1025-15" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">3</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * c +  a * t * (<span class="dv">1</span> - f) * c;  <span class="co">//Pr_Formal</span></span>
<span id="cb1025-16"><a href="ch-MPT.html#cb1025-16" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">4</span>] = a * (<span class="dv">1</span> - t) * f; <span class="co">//Pr_Mixed</span></span>
<span id="cb1025-17"><a href="ch-MPT.html#cb1025-17" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">5</span>] = a * t * f; <span class="co">//Pr_Correct</span></span>
<span id="cb1025-18"><a href="ch-MPT.html#cb1025-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1025-19"><a href="ch-MPT.html#cb1025-19" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1025-20"><a href="ch-MPT.html#cb1025-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(a | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1025-21"><a href="ch-MPT.html#cb1025-21" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(t | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1025-22"><a href="ch-MPT.html#cb1025-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(f | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1025-23"><a href="ch-MPT.html#cb1025-23" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(c | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1025-24"><a href="ch-MPT.html#cb1025-24" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> multinomial_lpmf(ans | theta);</span>
<span id="cb1025-25"><a href="ch-MPT.html#cb1025-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1025-26"><a href="ch-MPT.html#cb1025-26" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb1025-27"><a href="ch-MPT.html#cb1025-27" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> pred_ans[<span class="dv">5</span>];</span>
<span id="cb1025-28"><a href="ch-MPT.html#cb1025-28" aria-hidden="true" tabindex="-1"></a>  pred_ans = multinomial_rng(theta, <span class="dv">5</span>);</span>
<span id="cb1025-29"><a href="ch-MPT.html#cb1025-29" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Fit the model:</p>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1026-1"><a href="ch-MPT.html#cb1026-1" aria-hidden="true" tabindex="-1"></a>data_sMPT <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">N_trials =</span> N_trials,</span>
<span id="cb1026-2"><a href="ch-MPT.html#cb1026-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">ans =</span> <span class="fu">c</span>(ans)) </span></code></pre></div>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1027-1"><a href="ch-MPT.html#cb1027-1" aria-hidden="true" tabindex="-1"></a>mpt_mnm <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1027-2"><a href="ch-MPT.html#cb1027-2" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;mpt_mnm.stan&quot;</span>,</span>
<span id="cb1027-3"><a href="ch-MPT.html#cb1027-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb1027-4"><a href="ch-MPT.html#cb1027-4" aria-hidden="true" tabindex="-1"></a>fit_sMPT <span class="ot">&lt;-</span> <span class="fu">stan</span>(mpt_mnm, <span class="at">data =</span> data_sMPT)  </span></code></pre></div>
<p>Print out a summary of the posterior of the parameter of interest:</p>
<div class="sourceCode" id="cb1028"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1028-1"><a href="ch-MPT.html#cb1028-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_sMPT, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;t&quot;</span>, <span class="st">&quot;f&quot;</span>, <span class="st">&quot;c&quot;</span>))</span></code></pre></div>
<pre><code>##   mean 2.5% 97.5% n_eff Rhat
## a 0.75 0.69  0.81  4741    1
## t 0.85 0.78  0.90  4770    1
## f 0.79 0.72  0.85  4806    1
## c 0.20 0.09  0.34  4054    1</code></pre>
<p>What the model gives us is posterior distributions of each of the parameters <code>a</code>, <code>t</code>, <code>f</code>, <code>c</code>. From these we can derive the probabilities of producing the different observed responses, and the posterior predictive distributions, which could be used for model evaluation.</p>
<p>An important sanity check in modeling is checking whether the model can in principle recover the true parameters that generated the data; see Figure <a href="ch-MPT.html#fig:sMPT-posterior">18.3</a>.</p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1030-1"><a href="ch-MPT.html#cb1030-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(fit_sMPT) <span class="sc">%&gt;%</span></span>
<span id="cb1030-2"><a href="ch-MPT.html#cb1030-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">c</span>(<span class="st">&quot;a&quot;</span>,<span class="st">&quot;t&quot;</span>,<span class="st">&quot;f&quot;</span>,<span class="st">&quot;c&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1030-3"><a href="ch-MPT.html#cb1030-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mcmc_recover_hist</span>(<span class="at">true =</span> <span class="fu">c</span>(a_true, t_true, f_true, c_true)) <span class="sc">+</span></span>
<span id="cb1030-4"><a href="ch-MPT.html#cb1030-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:sMPT-posterior"></span>
<img src="bookdown_files/figure-html/sMPT-posterior-1.svg" alt="Posterior distributions and true values of the parameters of the simple MPT model (mpt_mnm.stan)." width="672" />
<p class="caption">
FIGURE 18.3: Posterior distributions and true values of the parameters of the simple MPT model (mpt_mnm.stan).
</p>
</div>
<p>The above figure shows that the model can indeed recover the true parameters fairly accurately.</p>
<p>The posterior distributions of the <span class="math inline">\(\boldsymbol{\theta}\)</span> parameters can also be summarized:</p>
<div class="sourceCode" id="cb1031"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1031-1"><a href="ch-MPT.html#cb1031-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_sMPT, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>))</span></code></pre></div>
<pre><code>##          mean 2.5% 97.5% n_eff Rhat
## theta[1] 0.25 0.19  0.31  4741    1
## theta[2] 0.13 0.09  0.18  4738    1
## theta[3] 0.03 0.01  0.06  4088    1
## theta[4] 0.09 0.06  0.13  4552    1
## theta[5] 0.50 0.43  0.57  4870    1</code></pre>
<p>These posteriors tell us the probability of producing each of the possible responses.
This model might be useful to estimate the latent parameters, <span class="math inline">\(a\)</span>, <span class="math inline">\(t\)</span>, <span class="math inline">\(f\)</span>, <span class="math inline">\(c\)</span>, but without further constraints it is unfalsifiable.</p>
<p>Recall that for the multinomial likelihood in section <a href="ch-MPT.html#sec-mult">18.1.1</a>, we had a simplex of size five, which means that we had four free parameters (since the fifth can be deduced based on the others). With five possible answers we can always estimate a vector of probabilities, <span class="math inline">\(\boldsymbol{\theta}\)</span>, that fits the data, in the same way that with two possible answers (e.g., zeros and ones), we can always estimate a probability <span class="math inline">\(\theta\)</span> that fits the data (using a Bernoulli or Binomial likelihood).
The MPT that we present here is just re-parametrizing the vector <span class="math inline">\(\boldsymbol{\theta}\)</span> of the multinomial likelihood (with the same number of free parameters). This means that it will always achieve a perfect fit. Also see exercise <a href="ch-MPT.html#exr:mpt-mnm">18.2</a>. This doesn’t mean that this MPT model is “useless”: Under the assumption that the model is meaningful, one can estimate its latent parameters and this estimation can have theoretical implications. If we want to be able to falsify this model, we’ll need to constrain it more, as we suggest below.</p>
</div>
<div id="sec-MPT-reg" class="section level3 hasAnchor" number="18.2.3">
<h3><span class="header-section-number">18.2.3</span> An MPT assuming by-item variability<a href="ch-MPT.html#sec-MPT-reg" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The use of aggregated data implies the assumption that the estimated parameters do not vary too much between subjects and items. If this assumption is incorrect, the analysis of aggregated data may lead to erroneous conclusions: reliance on aggregated data in the presence of parameter heterogeneity may lead to biased parameter estimates and the underestimation of credible intervals.</p>
<p>If it is known that <span class="math inline">\(f\)</span> is affected by the phonological complexity of the individual word (e.g., <em>cat</em> is easier to produce than <em>umbrella</em>), the previous model does not have a way to include that information.</p>
<p>Simulated data can be generated taking into account the <code>complexity</code> of the items. Assume here for simplicity that the complexity of items is scaled and centered; i.e., mean complexity is represented by <span class="math inline">\(0\)</span>, and the standard deviation is assumed to be <span class="math inline">\(1\)</span>. We will assume a regression model that determines the parameter, <span class="math inline">\(f\)</span>, as a function of the phonological complexity of each trial.</p>
<p>One important detail is that <code>f</code> is a probability and needs to be bounded between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. To make sure that this property is met, the computation of <code>f</code> for each item will be converted to probability space using the logistic function. This is achieved as follows.</p>
<p>Suppose that <span class="math inline">\(f&#39;\)</span> is a linear function of complexity. For example, two parameters <span class="math inline">\(\alpha_f\)</span> and <span class="math inline">\(\beta_f\)</span> (intercept and slope respectively) could determine how <span class="math inline">\(f&#39;\)</span> is affected by complexity:</p>
<p><span class="math inline">\(f&#39;_j=\alpha_f + complexity_j\cdot \beta_f\)</span>.</p>
<p>The parameters <span class="math inline">\(\alpha_f\)</span> and <span class="math inline">\(\beta_f\)</span> are defined in an unconstrained log-odds space (they can be any real number). The model that is fit then yields an <span class="math inline">\(f&#39;_j\)</span> value for each item <span class="math inline">\(j\)</span> in log-odds space. The log-odds value <span class="math inline">\(f&#39;_j\)</span> can be converted to a probability value <span class="math inline">\(f_{true}\)</span> by applying the logistic function (or the inverse logit, <span class="math inline">\(logit^{-1}\)</span>) to <span class="math inline">\(f&#39;\)</span>. Recall from the generalized linear model discussed earlier that if we have a model in log-odds space:</p>
<p><span class="math display">\[\begin{equation}
\log \left(\frac{p_j}{1-p_j}\right) = \alpha + \beta\cdot x_j = \mu_j
\end{equation}\]</span></p>
<p>Then we can recover the probability <span class="math inline">\(p_j\)</span> by solving for <span class="math inline">\(p_j\)</span>:</p>
<p><span class="math display">\[\begin{equation}
p_j = \frac{\exp(\mu_j)}{1+\exp(\mu_j)} = \frac{1}{1+\exp(-\mu_j)}
\end{equation}\]</span></p>
<p>The above is the logistic or inverse logit function: it takes as input <span class="math inline">\(\mu_j\)</span> and returns the corresponding probability <span class="math inline">\(p_j\)</span>. The <code>plogis</code> function in R carries out the calculation shown above.</p>
<div class="sourceCode" id="cb1033"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1033-1"><a href="ch-MPT.html#cb1033-1" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb1033-2"><a href="ch-MPT.html#cb1033-2" aria-hidden="true" tabindex="-1"></a>complexity <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N_obs) <span class="co"># by default mean = 0, sd = 1</span></span>
<span id="cb1033-3"><a href="ch-MPT.html#cb1033-3" aria-hidden="true" tabindex="-1"></a><span class="do">## choose some hypothetical values:</span></span>
<span id="cb1033-4"><a href="ch-MPT.html#cb1033-4" aria-hidden="true" tabindex="-1"></a>alpha_f <span class="ot">&lt;-</span> .<span class="dv">3</span></span>
<span id="cb1033-5"><a href="ch-MPT.html#cb1033-5" aria-hidden="true" tabindex="-1"></a><span class="co"># the negative sign indicates that</span></span>
<span id="cb1033-6"><a href="ch-MPT.html#cb1033-6" aria-hidden="true" tabindex="-1"></a><span class="co"># increased complexity will lead to a reduced value of f</span></span>
<span id="cb1033-7"><a href="ch-MPT.html#cb1033-7" aria-hidden="true" tabindex="-1"></a>beta_f <span class="ot">&lt;-</span> <span class="sc">-</span>.<span class="dv">3</span></span>
<span id="cb1033-8"><a href="ch-MPT.html#cb1033-8" aria-hidden="true" tabindex="-1"></a><span class="co"># f&#39; as a linear function of complexity</span></span>
<span id="cb1033-9"><a href="ch-MPT.html#cb1033-9" aria-hidden="true" tabindex="-1"></a>f_prime <span class="ot">&lt;-</span> alpha_f <span class="sc">+</span> complexity <span class="sc">*</span> beta_f</span>
<span id="cb1033-10"><a href="ch-MPT.html#cb1033-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(f_prime)</span></code></pre></div>
<pre><code>## [1]  0.468  0.369 -0.168  0.279  0.261 -0.215</code></pre>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1035-1"><a href="ch-MPT.html#cb1035-1" aria-hidden="true" tabindex="-1"></a><span class="do">## probabilities f for each item</span></span>
<span id="cb1035-2"><a href="ch-MPT.html#cb1035-2" aria-hidden="true" tabindex="-1"></a>f_true <span class="ot">&lt;-</span> <span class="fu">plogis</span>(f_prime)</span>
<span id="cb1035-3"><a href="ch-MPT.html#cb1035-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(f_true)</span></code></pre></div>
<pre><code>## [1] 0.615 0.591 0.458 0.569 0.565 0.447</code></pre>
<p>This change in our assumptions entails that the probability of each response changes depending on the item associated with each observation. The parameters <code>theta</code> now have to be a matrix. This is in R; in Stan, we will code it as an array of simplexes, i.e., an array of non-negative values that sums to 1.</p>
<p>We continue with the functions defined in <a href="ch-MPT.html#sec-mpt-data">18.2.2</a>, and the same values for <code>a_true</code>, <code>t_true</code>, and <code>c_true</code> as defined in that section. Since most of the equations depend on <code>f</code>, and <code>f</code> is a vector now, the outcomes are automatically vectors. But this is not the case for <code>theta_NR_v</code>, and thus we need to repeat the value.</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1037-1"><a href="ch-MPT.html#cb1037-1" aria-hidden="true" tabindex="-1"></a>theta_NR_v <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">Pr_NR</span>(a_true, t_true, f_true, c_true), N_obs)</span>
<span id="cb1037-2"><a href="ch-MPT.html#cb1037-2" aria-hidden="true" tabindex="-1"></a>theta_Neologism_v <span class="ot">&lt;-</span> <span class="fu">Pr_Neologism</span>(a_true, t_true, f_true, c_true)</span>
<span id="cb1037-3"><a href="ch-MPT.html#cb1037-3" aria-hidden="true" tabindex="-1"></a>theta_Formal_v <span class="ot">&lt;-</span> <span class="fu">Pr_Formal</span>(a_true, t_true, f_true, c_true)</span>
<span id="cb1037-4"><a href="ch-MPT.html#cb1037-4" aria-hidden="true" tabindex="-1"></a>theta_Mixed_v <span class="ot">&lt;-</span> <span class="fu">Pr_Mixed</span>(a_true, t_true, f_true, c_true)</span>
<span id="cb1037-5"><a href="ch-MPT.html#cb1037-5" aria-hidden="true" tabindex="-1"></a>theta_Correct_v <span class="ot">&lt;-</span> <span class="fu">Pr_Correct</span>(a_true, t_true, f_true, c_true)</span>
<span id="cb1037-6"><a href="ch-MPT.html#cb1037-6" aria-hidden="true" tabindex="-1"></a>theta_item <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(theta_NR_v,</span>
<span id="cb1037-7"><a href="ch-MPT.html#cb1037-7" aria-hidden="true" tabindex="-1"></a>                       theta_Neologism_v,</span>
<span id="cb1037-8"><a href="ch-MPT.html#cb1037-8" aria-hidden="true" tabindex="-1"></a>                       theta_Formal_v,</span>
<span id="cb1037-9"><a href="ch-MPT.html#cb1037-9" aria-hidden="true" tabindex="-1"></a>                       theta_Mixed_v,</span>
<span id="cb1037-10"><a href="ch-MPT.html#cb1037-10" aria-hidden="true" tabindex="-1"></a>                       theta_Correct_v),</span>
<span id="cb1037-11"><a href="ch-MPT.html#cb1037-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">ncol =</span> <span class="dv">5</span>)</span>
<span id="cb1037-12"><a href="ch-MPT.html#cb1037-12" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(theta_item)</span></code></pre></div>
<pre><code>## [1] 50  5</code></pre>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1039-1"><a href="ch-MPT.html#cb1039-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(theta_item,<span class="at">n =</span> <span class="dv">3</span>) </span></code></pre></div>
<pre><code>##      [,1]  [,2]   [,3]   [,4]  [,5]
## [1,] 0.25 0.260 0.0289 0.0461 0.415
## [2,] 0.25 0.276 0.0307 0.0443 0.399
## [3,] 0.25 0.366 0.0406 0.0344 0.309</code></pre>
<p>Store this in a data frame.</p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1041-1"><a href="ch-MPT.html#cb1041-1" aria-hidden="true" tabindex="-1"></a>sim_data_cx <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">item =</span> <span class="dv">1</span><span class="sc">:</span>N_obs,</span>
<span id="cb1041-2"><a href="ch-MPT.html#cb1041-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">complexity =</span> complexity,</span>
<span id="cb1041-3"><a href="ch-MPT.html#cb1041-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">w_ans =</span> <span class="fu">c</span>(<span class="fu">rcat</span>(N_obs,theta_item)))</span>
<span id="cb1041-4"><a href="ch-MPT.html#cb1041-4" aria-hidden="true" tabindex="-1"></a>sim_data_cx </span></code></pre></div>
<pre><code>## # A tibble: 50 × 3
##    item complexity w_ans
##   &lt;int&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1     1     -0.560     5
## 2     2     -0.230     2
## 3     3      1.56      2
## # … with 47 more rows</code></pre>
<p>The following model (saved in <code>mpt_cat.stan</code>) is essentially doing the same as the previous model but instead of fitting a multinomial to the summary of all the trials, it is fitting a categorical distribution to each individual observation. (This is analogous to the difference between the Bernoulli and Binomial distributions).</p>
<p>This is still not the appropriate model for the generative process that we are assuming in this section, because it still ignores the effect of complexity, but it is a good start.</p>
<div class="sourceCode" id="cb1043"><pre class="sourceCode stan fold-show"><code class="sourceCode stan"><span id="cb1043-1"><a href="ch-MPT.html#cb1043-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1043-2"><a href="ch-MPT.html#cb1043-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_obs;</span>
<span id="cb1043-3"><a href="ch-MPT.html#cb1043-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=<span class="dv">5</span>&gt; w_ans[N_obs];</span>
<span id="cb1043-4"><a href="ch-MPT.html#cb1043-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1043-5"><a href="ch-MPT.html#cb1043-5" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1043-6"><a href="ch-MPT.html#cb1043-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; a;</span>
<span id="cb1043-7"><a href="ch-MPT.html#cb1043-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; t;</span>
<span id="cb1043-8"><a href="ch-MPT.html#cb1043-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; f;</span>
<span id="cb1043-9"><a href="ch-MPT.html#cb1043-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; c;</span>
<span id="cb1043-10"><a href="ch-MPT.html#cb1043-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1043-11"><a href="ch-MPT.html#cb1043-11" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb1043-12"><a href="ch-MPT.html#cb1043-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[<span class="dv">5</span>] theta[N_obs];</span>
<span id="cb1043-13"><a href="ch-MPT.html#cb1043-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1043-14"><a href="ch-MPT.html#cb1043-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs){</span>
<span id="cb1043-15"><a href="ch-MPT.html#cb1043-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_NR:</span></span>
<span id="cb1043-16"><a href="ch-MPT.html#cb1043-16" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">1</span>] = <span class="dv">1</span> - a;</span>
<span id="cb1043-17"><a href="ch-MPT.html#cb1043-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Neologism:</span></span>
<span id="cb1043-18"><a href="ch-MPT.html#cb1043-18" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">2</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c) + a * t * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c);</span>
<span id="cb1043-19"><a href="ch-MPT.html#cb1043-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Formal:</span></span>
<span id="cb1043-20"><a href="ch-MPT.html#cb1043-20" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">3</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * c +  a * t * (<span class="dv">1</span> - f) * c;</span>
<span id="cb1043-21"><a href="ch-MPT.html#cb1043-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Mixed:</span></span>
<span id="cb1043-22"><a href="ch-MPT.html#cb1043-22" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">4</span>] = a * (<span class="dv">1</span> - t) * f;</span>
<span id="cb1043-23"><a href="ch-MPT.html#cb1043-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Correct:</span></span>
<span id="cb1043-24"><a href="ch-MPT.html#cb1043-24" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">5</span>] = a * t * f;</span>
<span id="cb1043-25"><a href="ch-MPT.html#cb1043-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1043-26"><a href="ch-MPT.html#cb1043-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1043-27"><a href="ch-MPT.html#cb1043-27" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1043-28"><a href="ch-MPT.html#cb1043-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(a | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1043-29"><a href="ch-MPT.html#cb1043-29" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(t | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1043-30"><a href="ch-MPT.html#cb1043-30" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(f | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1043-31"><a href="ch-MPT.html#cb1043-31" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(c | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1043-32"><a href="ch-MPT.html#cb1043-32" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1043-33"><a href="ch-MPT.html#cb1043-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> categorical_lpmf(w_ans[n] | theta[n]);</span>
<span id="cb1043-34"><a href="ch-MPT.html#cb1043-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1043-35"><a href="ch-MPT.html#cb1043-35" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb1043-36"><a href="ch-MPT.html#cb1043-36" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> pred_w_ans[N_obs];</span>
<span id="cb1043-37"><a href="ch-MPT.html#cb1043-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1043-38"><a href="ch-MPT.html#cb1043-38" aria-hidden="true" tabindex="-1"></a>    pred_w_ans[n] = categorical_rng(theta[n]);</span>
<span id="cb1043-39"><a href="ch-MPT.html#cb1043-39" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>An important aspect of the previous model is that <code>theta</code> is declared as <code>simplex[5] theta[N_obs]</code>. This means that <code>theta</code> is an array of simplexes and thus has now two dimensions: each element of the array (of length <code>N_obs</code>) is a simplex and sums to one. That’s why we iterate over the <code>N_obs</code>. However, one limitation of the previous model is that the latent parameters <code>a</code>, <code>t</code>, <code>f</code>, <code>c</code> are declared as <code>real</code> and they do not vary in each iteration of the loop. Before moving to the next section, you might want to do exercise <a href="ch-MPT.html#exr:edit-mpt-cat">18.3</a>, where you are asked to edit the previous chunk of code to incorporate the fact that <code>f</code> is now a transformed parameter that depends on the trial information and two new parameters.</p>
</div>
<div id="sec-MPT-h" class="section level3 hasAnchor" number="18.2.4">
<h3><span class="header-section-number">18.2.4</span> A hierarchical MPT<a href="ch-MPT.html#sec-MPT-h" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The previous model doesn’t take into account that subjects might vary (and neither does the modification to this model that is suggested in exercise <a href="ch-MPT.html#exr:edit-mpt-cat">18.3</a>). Let’s focus on taking into account the differences between subjects.</p>
<p>Different subjects might not be equally motivated to do the task. This can be accounted by adding a hierarchical structure to the parameter <code>a</code>, the probability of initiating an attempt. Begin by simulating some data that incorporates by-subject variability.</p>
<p>First, define the number of items and subjects, and the number of observations:</p>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1044-1"><a href="ch-MPT.html#cb1044-1" aria-hidden="true" tabindex="-1"></a>N_item <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb1044-2"><a href="ch-MPT.html#cb1044-2" aria-hidden="true" tabindex="-1"></a>N_subj <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb1044-3"><a href="ch-MPT.html#cb1044-3" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> N_item <span class="sc">*</span> N_subj </span></code></pre></div>
<p>Then, generate a vector for subjects and for items. Assume here that each subject sees each item.</p>
<div class="sourceCode" id="cb1045"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1045-1"><a href="ch-MPT.html#cb1045-1" aria-hidden="true" tabindex="-1"></a>subj <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>N_subj, <span class="at">each =</span> N_item)</span>
<span id="cb1045-2"><a href="ch-MPT.html#cb1045-2" aria-hidden="true" tabindex="-1"></a>item <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>N_item, <span class="at">time =</span> N_subj)</span></code></pre></div>
<p>A vector representing complexity is created for the number of items we have, and this vector is repeated as many times as there are subjects:</p>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1046-1"><a href="ch-MPT.html#cb1046-1" aria-hidden="true" tabindex="-1"></a>complexity <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">rnorm</span>(N_item), <span class="at">times =</span> N_subj)</span></code></pre></div>
<p>Next, create a data frame with all the above information:</p>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1047-1"><a href="ch-MPT.html#cb1047-1" aria-hidden="true" tabindex="-1"></a>(exp_sim <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">subj =</span> subj,</span>
<span id="cb1047-2"><a href="ch-MPT.html#cb1047-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">item =</span> item,</span>
<span id="cb1047-3"><a href="ch-MPT.html#cb1047-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">complexity =</span> complexity)) </span></code></pre></div>
<pre><code>## # A tibble: 600 × 3
##    subj  item complexity
##   &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;
## 1     1     1     -0.560
## 2     1     2     -0.230
## 3     1     3      1.56 
## # … with 597 more rows</code></pre>
<p>To create subject-level variability in the data, a between-subject standard deviation needs to be defined. This standard deviation represents the deviations of subjects about the grand mean. We are defining this adjustment in log-odds space.</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1049-1"><a href="ch-MPT.html#cb1049-1" aria-hidden="true" tabindex="-1"></a><span class="co"># New parameters, in log-odds space:</span></span>
<span id="cb1049-2"><a href="ch-MPT.html#cb1049-2" aria-hidden="true" tabindex="-1"></a>tau_u_a <span class="ot">&lt;-</span> <span class="fl">1.1</span></span>
<span id="cb1049-3"><a href="ch-MPT.html#cb1049-3" aria-hidden="true" tabindex="-1"></a><span class="do">## generate subject adjustments in log-odds space:</span></span>
<span id="cb1049-4"><a href="ch-MPT.html#cb1049-4" aria-hidden="true" tabindex="-1"></a>u_a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N_subj, <span class="dv">0</span>, tau_u_a)</span>
<span id="cb1049-5"><a href="ch-MPT.html#cb1049-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(u_a) </span></code></pre></div>
<pre><code>##  num [1:30] -1.175 -0.24 -1.129 -0.802 -0.688 ...</code></pre>
<p>Given the fixed <code>a_true</code> probability value of 0.75, the subject-level values for individual <code>a_true</code> can be derived by (a) first converting the overall <code>a_true</code> value to log-odds space, (b) adding the by-subject adjustment to this converted overall value, and (c) then converting back to probability space using the logistic or inverse logit (<code>plogis</code>) function. Essentially we generate data assuming the following:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
a_{h,n}&#39; &amp;= \alpha_a + u_{a,subj[n]}\\
a_{h,n} &amp;= logit^{-1}(a_{h,n}&#39;)
\end{aligned}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(u_{a,subj[n]}\)</span> is a vector with the same length as the total number of observations. The meaning of this notation was explained in the section <a href="ch-complexstan.html#sec-hierstan">11.1</a>.</p>
<p>This is done in R as follows:</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1051-1"><a href="ch-MPT.html#cb1051-1" aria-hidden="true" tabindex="-1"></a>a_true <span class="ot">&lt;-</span> .<span class="dv">75</span> <span class="co"># as before</span></span>
<span id="cb1051-2"><a href="ch-MPT.html#cb1051-2" aria-hidden="true" tabindex="-1"></a><span class="do">## convert the intercept to log-odds space:</span></span>
<span id="cb1051-3"><a href="ch-MPT.html#cb1051-3" aria-hidden="true" tabindex="-1"></a>alpha_a <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(a_true)</span>
<span id="cb1051-4"><a href="ch-MPT.html#cb1051-4" aria-hidden="true" tabindex="-1"></a><span class="do">## a_h&#39; in log-odds space:</span></span>
<span id="cb1051-5"><a href="ch-MPT.html#cb1051-5" aria-hidden="true" tabindex="-1"></a>a_h_prime <span class="ot">&lt;-</span>  alpha_a <span class="sc">+</span> u_a[subj]</span>
<span id="cb1051-6"><a href="ch-MPT.html#cb1051-6" aria-hidden="true" tabindex="-1"></a><span class="do">## convert back to probability space</span></span>
<span id="cb1051-7"><a href="ch-MPT.html#cb1051-7" aria-hidden="true" tabindex="-1"></a>a_true_h <span class="ot">&lt;-</span> <span class="fu">plogis</span>(a_h_prime)</span>
<span id="cb1051-8"><a href="ch-MPT.html#cb1051-8" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(a_true_h) </span></code></pre></div>
<pre><code>##  num [1:600] 0.481 0.481 0.481 0.481 0.481 ...</code></pre>
<p>What this achieves mathematically is adding varying intercepts by subjects to <code>alpha_a</code>, and then the values adjusted by subject are saved in probability space.</p>
<p>As before, <code>f_true</code> is computed as a function of complexity:</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1053-1"><a href="ch-MPT.html#cb1053-1" aria-hidden="true" tabindex="-1"></a>alpha_f <span class="ot">&lt;-</span> .<span class="dv">3</span>; beta_f <span class="ot">&lt;-</span> <span class="sc">-</span>.<span class="dv">3</span></span>
<span id="cb1053-2"><a href="ch-MPT.html#cb1053-2" aria-hidden="true" tabindex="-1"></a>f_true <span class="ot">&lt;-</span> <span class="fu">plogis</span>(alpha_f <span class="sc">+</span> complexity <span class="sc">*</span> beta_f)</span></code></pre></div>
<p>We continue with the same probability functions and the rest of the true values remain the same as well.</p>
<div class="sourceCode" id="cb1054"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1054-1"><a href="ch-MPT.html#cb1054-1" aria-hidden="true" tabindex="-1"></a>t_true <span class="ot">&lt;-</span> .<span class="dv">9</span>; c_true <span class="ot">&lt;-</span> .<span class="dv">1</span></span>
<span id="cb1054-2"><a href="ch-MPT.html#cb1054-2" aria-hidden="true" tabindex="-1"></a>Pr_NR <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1054-3"><a href="ch-MPT.html#cb1054-3" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span> <span class="sc">-</span> a</span>
<span id="cb1054-4"><a href="ch-MPT.html#cb1054-4" aria-hidden="true" tabindex="-1"></a>Pr_Neologism <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1054-5"><a href="ch-MPT.html#cb1054-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> c) <span class="sc">+</span> a <span class="sc">*</span> t <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> c)</span>
<span id="cb1054-6"><a href="ch-MPT.html#cb1054-6" aria-hidden="true" tabindex="-1"></a>Pr_Formal <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1054-7"><a href="ch-MPT.html#cb1054-7" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> c <span class="sc">+</span>  a <span class="sc">*</span> t <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> f) <span class="sc">*</span> c</span>
<span id="cb1054-8"><a href="ch-MPT.html#cb1054-8" aria-hidden="true" tabindex="-1"></a>Pr_Mixed <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1054-9"><a href="ch-MPT.html#cb1054-9" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> t) <span class="sc">*</span> f</span>
<span id="cb1054-10"><a href="ch-MPT.html#cb1054-10" aria-hidden="true" tabindex="-1"></a>Pr_Correct <span class="ot">&lt;-</span> <span class="cf">function</span>(a, t, f, c)</span>
<span id="cb1054-11"><a href="ch-MPT.html#cb1054-11" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">*</span> t <span class="sc">*</span> f</span></code></pre></div>
<p>Now, we can define the probabilities of different outcomes:</p>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1055-1"><a href="ch-MPT.html#cb1055-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Aux. parameters that define the probabilities:</span></span>
<span id="cb1055-2"><a href="ch-MPT.html#cb1055-2" aria-hidden="true" tabindex="-1"></a>theta_NR_v_h <span class="ot">&lt;-</span> <span class="fu">Pr_NR</span>(a_true_h, t_true, f_true, c_true) </span>
<span id="cb1055-3"><a href="ch-MPT.html#cb1055-3" aria-hidden="true" tabindex="-1"></a>theta_Neologism_v_h <span class="ot">&lt;-</span> <span class="fu">Pr_Neologism</span>(a_true_h, t_true, f_true, c_true)</span>
<span id="cb1055-4"><a href="ch-MPT.html#cb1055-4" aria-hidden="true" tabindex="-1"></a>theta_Formal_v_h <span class="ot">&lt;-</span> <span class="fu">Pr_Formal</span>(a_true_h, t_true, f_true, c_true)</span>
<span id="cb1055-5"><a href="ch-MPT.html#cb1055-5" aria-hidden="true" tabindex="-1"></a>theta_Mixed_v_h <span class="ot">&lt;-</span> <span class="fu">Pr_Mixed</span>(a_true_h, t_true, f_true, c_true)</span>
<span id="cb1055-6"><a href="ch-MPT.html#cb1055-6" aria-hidden="true" tabindex="-1"></a>theta_Correct_v_h <span class="ot">&lt;-</span> <span class="fu">Pr_Correct</span>(a_true_h, t_true, f_true, c_true)</span>
<span id="cb1055-7"><a href="ch-MPT.html#cb1055-7" aria-hidden="true" tabindex="-1"></a>theta_h <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb1055-8"><a href="ch-MPT.html#cb1055-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(theta_NR_v_h,</span>
<span id="cb1055-9"><a href="ch-MPT.html#cb1055-9" aria-hidden="true" tabindex="-1"></a>    theta_Neologism_v_h,</span>
<span id="cb1055-10"><a href="ch-MPT.html#cb1055-10" aria-hidden="true" tabindex="-1"></a>    theta_Formal_v_h,</span>
<span id="cb1055-11"><a href="ch-MPT.html#cb1055-11" aria-hidden="true" tabindex="-1"></a>    theta_Mixed_v_h,</span>
<span id="cb1055-12"><a href="ch-MPT.html#cb1055-12" aria-hidden="true" tabindex="-1"></a>    theta_Correct_v_h),</span>
<span id="cb1055-13"><a href="ch-MPT.html#cb1055-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol =</span> <span class="dv">5</span>)</span>
<span id="cb1055-14"><a href="ch-MPT.html#cb1055-14" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(theta_h)</span></code></pre></div>
<pre><code>## [1] 600   5</code></pre>
<p>The probability specifications shown above can now generate the simulated data:</p>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1057-1"><a href="ch-MPT.html#cb1057-1" aria-hidden="true" tabindex="-1"></a>(sim_data_h <span class="ot">&lt;-</span> <span class="fu">mutate</span>(exp_sim,</span>
<span id="cb1057-2"><a href="ch-MPT.html#cb1057-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">w_ans =</span> <span class="fu">rcat</span>(N_obs,theta_h)))</span></code></pre></div>
<pre><code>## # A tibble: 600 × 4
##    subj  item complexity w_ans
##   &lt;int&gt; &lt;int&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1     1     1     -0.560     2
## 2     1     2     -0.230     1
## 3     1     3      1.56      1
## # … with 597 more rows</code></pre>
<p>We define now the following model; we omit the steps with <span class="math inline">\(f&#39;\)</span> and <span class="math inline">\(a&#39;\)</span> and we directly apply the logistic function to a regression. The parameters <span class="math inline">\(t\)</span>, <span class="math inline">\(c\)</span> do not vary by item or subject and therefore do not have the subscript <span class="math inline">\(_n\)</span>. We start by defining relatively weak priors for all the parameters in the following model.</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\alpha_a, \alpha_f, \beta_f &amp;\sim \mathit{Normal}(0, 2)\\
t,c &amp;\sim \mathit{Beta}(2, 2)\\
\tau_u &amp;\sim \mathit{Normal}(0, 1)\\
u_a &amp;\sim \mathit{Normal}(0, \tau_{u_a})\\
a_n &amp;= logit^{-1}(\alpha_a + u_{a,subj[n]})\\
f_n &amp;= logit^{-1}(\alpha_f + complexity_n \cdot \beta_f)\\
\theta_{n,nr} &amp;= 1 - a_n \\
\theta_{n,neol.} &amp;= a_n \cdot (1-t) \cdot (1-f_n) \cdot (1-c) +  a_n \cdot t \cdot (1-f_n) \cdot (1-c)\\
\theta_{n,formal} &amp;= a_n \cdot (1-t) \cdot (1-f_n) \cdot c +  a_n \cdot t \cdot (1-f_n) \cdot c\\
\theta_{n,mix} &amp;= a_n \cdot (1-t) \cdot f_n\\
\theta_{n,corr} &amp;= a_n \cdot t \cdot f_n\\
\theta_n &amp;= \{\theta_{n, nr}, \theta_{n, neol.}, \theta_{n, formal}, \theta_{n, mix}, \theta_{n, corr}\}\\
ans_n &amp;\sim \mathit{Categorical}(\theta_n)
\end{aligned}
\end{equation}\]</span></p>
<p>The corresponding Stan model <code>mpt_h.stan</code> will look like this:</p>
<div class="sourceCode" id="cb1059"><pre class="sourceCode stan fold-show"><code class="sourceCode stan"><span id="cb1059-1"><a href="ch-MPT.html#cb1059-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1059-2"><a href="ch-MPT.html#cb1059-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>&gt; N_obs;</span>
<span id="cb1059-3"><a href="ch-MPT.html#cb1059-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>, <span class="kw">upper</span> = <span class="dv">5</span>&gt; w_ans[N_obs];</span>
<span id="cb1059-4"><a href="ch-MPT.html#cb1059-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> complexity[N_obs];</span>
<span id="cb1059-5"><a href="ch-MPT.html#cb1059-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>&gt; N_subj;</span>
<span id="cb1059-6"><a href="ch-MPT.html#cb1059-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>, <span class="kw">upper</span> = N_subj&gt; subj[N_obs];</span>
<span id="cb1059-7"><a href="ch-MPT.html#cb1059-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1059-8"><a href="ch-MPT.html#cb1059-8" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1059-9"><a href="ch-MPT.html#cb1059-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; t;</span>
<span id="cb1059-10"><a href="ch-MPT.html#cb1059-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>, <span class="kw">upper</span> = <span class="dv">1</span>&gt; c;</span>
<span id="cb1059-11"><a href="ch-MPT.html#cb1059-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha_a;</span>
<span id="cb1059-12"><a href="ch-MPT.html#cb1059-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span> = <span class="dv">0</span>&gt; tau_u_a;</span>
<span id="cb1059-13"><a href="ch-MPT.html#cb1059-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_subj] u_a;</span>
<span id="cb1059-14"><a href="ch-MPT.html#cb1059-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha_f;</span>
<span id="cb1059-15"><a href="ch-MPT.html#cb1059-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta_f;</span>
<span id="cb1059-16"><a href="ch-MPT.html#cb1059-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1059-17"><a href="ch-MPT.html#cb1059-17" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb1059-18"><a href="ch-MPT.html#cb1059-18" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[<span class="dv">5</span>] theta[N_obs];</span>
<span id="cb1059-19"><a href="ch-MPT.html#cb1059-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_obs){</span>
<span id="cb1059-20"><a href="ch-MPT.html#cb1059-20" aria-hidden="true" tabindex="-1"></a>    <span class="dt">real</span> a = inv_logit(alpha_a + u_a[subj[n]]);</span>
<span id="cb1059-21"><a href="ch-MPT.html#cb1059-21" aria-hidden="true" tabindex="-1"></a>    <span class="dt">real</span> f = inv_logit(alpha_f + complexity[n] * beta_f);</span>
<span id="cb1059-22"><a href="ch-MPT.html#cb1059-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_NR</span></span>
<span id="cb1059-23"><a href="ch-MPT.html#cb1059-23" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">1</span>] = <span class="dv">1</span> - a;</span>
<span id="cb1059-24"><a href="ch-MPT.html#cb1059-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Neologism</span></span>
<span id="cb1059-25"><a href="ch-MPT.html#cb1059-25" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">2</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c) +</span>
<span id="cb1059-26"><a href="ch-MPT.html#cb1059-26" aria-hidden="true" tabindex="-1"></a>      a * t * (<span class="dv">1</span> - f) * (<span class="dv">1</span> - c);</span>
<span id="cb1059-27"><a href="ch-MPT.html#cb1059-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Formal</span></span>
<span id="cb1059-28"><a href="ch-MPT.html#cb1059-28" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">3</span>] = a * (<span class="dv">1</span> - t) * (<span class="dv">1</span> - f) * c</span>
<span id="cb1059-29"><a href="ch-MPT.html#cb1059-29" aria-hidden="true" tabindex="-1"></a>      + a * t * (<span class="dv">1</span> - f) * c;</span>
<span id="cb1059-30"><a href="ch-MPT.html#cb1059-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Mixed</span></span>
<span id="cb1059-31"><a href="ch-MPT.html#cb1059-31" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">4</span>] = a * (<span class="dv">1</span> - t) * f;</span>
<span id="cb1059-32"><a href="ch-MPT.html#cb1059-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pr_Correct</span></span>
<span id="cb1059-33"><a href="ch-MPT.html#cb1059-33" aria-hidden="true" tabindex="-1"></a>    theta[n, <span class="dv">5</span>] = a * t * f;</span>
<span id="cb1059-34"><a href="ch-MPT.html#cb1059-34" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1059-35"><a href="ch-MPT.html#cb1059-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1059-36"><a href="ch-MPT.html#cb1059-36" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1059-37"><a href="ch-MPT.html#cb1059-37" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(t | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1059-38"><a href="ch-MPT.html#cb1059-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> beta_lpdf(c | <span class="dv">2</span>, <span class="dv">2</span>);</span>
<span id="cb1059-39"><a href="ch-MPT.html#cb1059-39" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> normal_lpdf(alpha_a | <span class="dv">0</span>, <span class="dv">2</span>);</span>
<span id="cb1059-40"><a href="ch-MPT.html#cb1059-40" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> normal_lpdf(alpha_f | <span class="dv">0</span>, <span class="dv">2</span>);</span>
<span id="cb1059-41"><a href="ch-MPT.html#cb1059-41" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> normal_lpdf(beta_f | <span class="dv">0</span>, <span class="dv">2</span>);</span>
<span id="cb1059-42"><a href="ch-MPT.html#cb1059-42" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> normal_lpdf(u_a | <span class="dv">0</span>, tau_u_a);</span>
<span id="cb1059-43"><a href="ch-MPT.html#cb1059-43" aria-hidden="true" tabindex="-1"></a>  <span class="kw">target +=</span> normal_lpdf(tau_u_a | <span class="dv">0</span>, <span class="dv">1</span>) - normal_lccdf(<span class="dv">0</span> | <span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb1059-44"><a href="ch-MPT.html#cb1059-44" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1059-45"><a href="ch-MPT.html#cb1059-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span>  categorical_lpmf(w_ans[n] | theta[n]);</span>
<span id="cb1059-46"><a href="ch-MPT.html#cb1059-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1059-47"><a href="ch-MPT.html#cb1059-47" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span>{</span>
<span id="cb1059-48"><a href="ch-MPT.html#cb1059-48" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span> = <span class="dv">1</span>, <span class="kw">upper</span> = <span class="dv">5</span>&gt; pred_w_ans[N_obs];</span>
<span id="cb1059-49"><a href="ch-MPT.html#cb1059-49" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(n <span class="cf">in</span> <span class="dv">1</span>:N_obs)</span>
<span id="cb1059-50"><a href="ch-MPT.html#cb1059-50" aria-hidden="true" tabindex="-1"></a>    pred_w_ans[n] = categorical_rng(theta[n]);</span>
<span id="cb1059-51"><a href="ch-MPT.html#cb1059-51" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>For ease of exposition, we are not using the non-centered parametrization discussed previously in <a href="ch-complexstan.html#sec-uncorrstan">11.1.2</a>. We could also apply it here and it will speed up and improve the convergence of the model; see Exercise <a href="ch-MPT.html#exr:mpt">18.4</a>.</p>
<p>It would be a good idea to plot prior predictive distributions for this model; we skip this step here. Next, fit the model to the simulated data, by first defining the data as a list:</p>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1060-1"><a href="ch-MPT.html#cb1060-1" aria-hidden="true" tabindex="-1"></a>sim_list_h <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">N_obs =</span> <span class="fu">nrow</span>(sim_data_h),</span>
<span id="cb1060-2"><a href="ch-MPT.html#cb1060-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">w_ans =</span> sim_data_h<span class="sc">$</span>w_ans,</span>
<span id="cb1060-3"><a href="ch-MPT.html#cb1060-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">N_subj =</span> <span class="fu">max</span>(sim_data_h<span class="sc">$</span>subj),</span>
<span id="cb1060-4"><a href="ch-MPT.html#cb1060-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">subj =</span> sim_data_h<span class="sc">$</span>subj,</span>
<span id="cb1060-5"><a href="ch-MPT.html#cb1060-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">complexity =</span> sim_data_h<span class="sc">$</span>complexity)</span></code></pre></div>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1061-1"><a href="ch-MPT.html#cb1061-1" aria-hidden="true" tabindex="-1"></a>mpt_h <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1061-2"><a href="ch-MPT.html#cb1061-2" aria-hidden="true" tabindex="-1"></a>                     <span class="st">&quot;mpt_h.stan&quot;</span>,</span>
<span id="cb1061-3"><a href="ch-MPT.html#cb1061-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb1061-4"><a href="ch-MPT.html#cb1061-4" aria-hidden="true" tabindex="-1"></a>fit_mpt_h <span class="ot">&lt;-</span> <span class="fu">stan</span>(mpt_h, <span class="at">data =</span> sim_list_h)  </span></code></pre></div>
<p>Print out a summary of the posterior.</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1062-1"><a href="ch-MPT.html#cb1062-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_mpt_h,</span>
<span id="cb1062-2"><a href="ch-MPT.html#cb1062-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;t&quot;</span>, <span class="st">&quot;c&quot;</span>, <span class="st">&quot;tau_u_a&quot;</span>, <span class="st">&quot;alpha_a&quot;</span>, <span class="st">&quot;alpha_f&quot;</span>, <span class="st">&quot;beta_f&quot;</span>))</span></code></pre></div>
<pre><code>##          mean  2.5% 97.5% n_eff Rhat
## t        0.91  0.87  0.94  4219    1
## c        0.11  0.07  0.16  4346    1
## tau_u_a  0.99  0.66  1.41  2050    1
## alpha_a  1.02  0.61  1.41  1408    1
## alpha_f  0.25  0.05  0.45  4338    1
## beta_f  -0.22 -0.43 -0.01  3861    1</code></pre>
<p>If we had fit this to real data, we would now conclude that (i) given the value of <code>beta_f</code>, complexity has an adverse effect on the probability of retrieving the correct phonemes, and (ii) given the value of <code>tau_u_a</code>, there is a great deal of variation in the subjects’ probability of initiating an attempt at each trial. Furthermore, if we had some expectation about <span class="math inline">\(t\)</span> and <span class="math inline">\(c\)</span> based on previous research we could conclude that our results are in line (or not) with previous findings.</p>
<p>One could inspect how one unit of complexity is affecting the probability of retrieving the correct phoneme (<span class="math inline">\(f\)</span>). We first derive the value of <code>f</code> for an item of zero complexity (that is <span class="math inline">\(\alpha_{f} + 0 \times \beta_{f}\)</span>) and then the value of <code>f</code> for an item with a complexity of one (<span class="math inline">\(\alpha_{f} + 1 \times \beta_{f}\)</span>). We are interested in summarizing the difference between the two:</p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1064-1"><a href="ch-MPT.html#cb1064-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(fit_mpt_h) <span class="sc">%&gt;%</span></span>
<span id="cb1064-2"><a href="ch-MPT.html#cb1064-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(alpha_f, beta_f) <span class="sc">%&gt;%</span></span>
<span id="cb1064-3"><a href="ch-MPT.html#cb1064-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">f_0 =</span> <span class="fu">plogis</span>(alpha_f),</span>
<span id="cb1064-4"><a href="ch-MPT.html#cb1064-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">f_1 =</span> <span class="fu">plogis</span>(alpha_f <span class="sc">+</span> beta_f),</span>
<span id="cb1064-5"><a href="ch-MPT.html#cb1064-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">diff_f =</span> f_1 <span class="sc">-</span> f_0) <span class="sc">%&gt;%</span></span>
<span id="cb1064-6"><a href="ch-MPT.html#cb1064-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">Estimate =</span> <span class="fu">mean</span>(diff_f),</span>
<span id="cb1064-7"><a href="ch-MPT.html#cb1064-7" aria-hidden="true" tabindex="-1"></a>          <span class="st">`</span><span class="at">2.5%</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">quantile</span>(diff_f, <span class="fl">0.025</span>),</span>
<span id="cb1064-8"><a href="ch-MPT.html#cb1064-8" aria-hidden="true" tabindex="-1"></a>          <span class="st">`</span><span class="at">97.5%</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">quantile</span>(diff_f, <span class="fl">0.975</span>))  </span></code></pre></div>
<pre><code>##   Estimate   2.5%    97.5%
## 1  -0.0543 -0.107 -0.00366</code></pre>
<p>One further interesting step could be to develop a competing model that assumes a different latent process, and then comparing the performance of the MPT with this competing model, using Bayes factors or K-fold-CV (or both).</p>
<p>Since we generated the data based on known latent parameters, we also plot the posteriors together with the true values of the parameters in Figure <a href="ch-MPT.html#fig:mpt-h">18.4</a>. This is something that we can only do with simulated data.</p>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1066-1"><a href="ch-MPT.html#cb1066-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(fit_mpt_h) <span class="sc">%&gt;%</span></span>
<span id="cb1066-2"><a href="ch-MPT.html#cb1066-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(tau_u_a, alpha_a, t, alpha_f, beta_f, c) <span class="sc">%&gt;%</span></span>
<span id="cb1066-3"><a href="ch-MPT.html#cb1066-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mcmc_recover_hist</span>(<span class="at">true =</span> <span class="fu">c</span>(tau_u_a,</span>
<span id="cb1066-4"><a href="ch-MPT.html#cb1066-4" aria-hidden="true" tabindex="-1"></a>                             <span class="fu">qlogis</span>(a_true),</span>
<span id="cb1066-5"><a href="ch-MPT.html#cb1066-5" aria-hidden="true" tabindex="-1"></a>                             t_true, alpha_f,</span>
<span id="cb1066-6"><a href="ch-MPT.html#cb1066-6" aria-hidden="true" tabindex="-1"></a>                             beta_f, c_true))  </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:mpt-h"></span>
<img src="bookdown_files/figure-html/mpt-h-1.svg" alt="Posterior of the hierarchical MPT with true values as vertical lines (model `mpt_h.stan`)." width="672" />
<p class="caption">
FIGURE 18.4: Posterior of the hierarchical MPT with true values as vertical lines (model <code>mpt_h.stan</code>).
</p>
</div>
<p>If everything is correctly defined in the model, we should be able to generate posterior predictive data based on our estimates that looks quite similar to the simulated data; see Figure <a href="ch-MPT.html#fig:aggMPT-h">18.5</a>. The error bars in <span class="math inline">\(y_rep\)</span> include 90% of the probability mass of the predictive distribution (this is a default of <code>ppc_bars()</code>). In a well calibrated model, the data (<span class="math inline">\(y\)</span>, here the proportion of answers of each type) should be inside the error bars 90% of the time.</p>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1067-1"><a href="ch-MPT.html#cb1067-1" aria-hidden="true" tabindex="-1"></a>gen_data <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">extract</span>(fit_mpt_h)<span class="sc">$</span>pred_w_ans</span>
<span id="cb1067-2"><a href="ch-MPT.html#cb1067-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_bars</span>(sim_list_h<span class="sc">$</span>w_ans, gen_data) <span class="sc">+</span></span>
<span id="cb1067-3"><a href="ch-MPT.html#cb1067-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span> (<span class="st">&quot;Hierarchical model&quot;</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:aggMPT-h"></span>
<img src="bookdown_files/figure-html/aggMPT-h-1.svg" alt="Posterior predictive check for aggregated data in the hierarchical MPT model" width="672" />
<p class="caption">
FIGURE 18.5: Posterior predictive check for aggregated data in the hierarchical MPT model
</p>
</div>
<p>It is also useful to look at the individual subjects’ posteriors; these are shown in Figure <a href="ch-MPT.html#fig:pMPT-h">18.6</a>.</p>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1068-1"><a href="ch-MPT.html#cb1068-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_bars_grouped</span>(sim_list_h<span class="sc">$</span>w_ans, </span>
<span id="cb1068-2"><a href="ch-MPT.html#cb1068-2" aria-hidden="true" tabindex="-1"></a>                 gen_data, <span class="at">group =</span> subj) <span class="sc">+</span></span>
<span id="cb1068-3"><a href="ch-MPT.html#cb1068-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span> (<span class="st">&quot;By-subject plot for the hierarchical model&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:pMPT-h"></span>
<img src="bookdown_files/figure-html/pMPT-h-1.svg" alt="Individual subjects in the hierarchical MPT model." width="672" />
<p class="caption">
FIGURE 18.6: Individual subjects in the hierarchical MPT model.
</p>
</div>
<p>But what about the first <em>non-hierarchical</em> MPT model (<code>mpt_cat.stan</code>)?:</p>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1069-1"><a href="ch-MPT.html#cb1069-1" aria-hidden="true" tabindex="-1"></a>mpt_cat <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1069-2"><a href="ch-MPT.html#cb1069-2" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;mpt_cat.stan&quot;</span>,</span>
<span id="cb1069-3"><a href="ch-MPT.html#cb1069-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb1069-4"><a href="ch-MPT.html#cb1069-4" aria-hidden="true" tabindex="-1"></a>fit_sh <span class="ot">&lt;-</span> <span class="fu">stan</span>(mpt_cat, <span class="at">data =</span> sim_list_h)  </span></code></pre></div>
<p>The aggregated data looks great (Figure <a href="ch-MPT.html#fig:aggMPT-nh">18.7</a>).</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1070-1"><a href="ch-MPT.html#cb1070-1" aria-hidden="true" tabindex="-1"></a>gen_data_sMPT <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">extract</span>(fit_sh)<span class="sc">$</span>pred_w_ans</span>
<span id="cb1070-2"><a href="ch-MPT.html#cb1070-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_bars</span>(sim_list_h<span class="sc">$</span>w_ans, gen_data_sMPT) <span class="sc">+</span></span>
<span id="cb1070-3"><a href="ch-MPT.html#cb1070-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span> (<span class="st">&quot;Non-hierarchical model&quot;</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:aggMPT-nh"></span>
<img src="bookdown_files/figure-html/aggMPT-nh-1.svg" alt="Posterior predictive check for aggregated data in a non-hierarchical MPT model (mpt_cat.stan)." width="672" />
<p class="caption">
FIGURE 18.7: Posterior predictive check for aggregated data in a non-hierarchical MPT model (mpt_cat.stan).
</p>
</div>
<p>However, the fit to individual subjects looks less good (Figure <a href="ch-MPT.html#fig:pMPT">18.8</a>) for the non-hierarchical model: The error bars of the predicted distribution do not include the observed proportion of answers for many of the subjects.</p>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1071-1"><a href="ch-MPT.html#cb1071-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_bars_grouped</span>(sim_list_h<span class="sc">$</span>w_ans, gen_data_sMPT, <span class="at">group =</span> subj) <span class="sc">+</span></span>
<span id="cb1071-2"><a href="ch-MPT.html#cb1071-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span> (<span class="st">&quot;By-subject plot for the non-hierarchical model&quot;</span>) </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:pMPT"></span>
<img src="bookdown_files/figure-html/pMPT-1.svg" alt="Individual subjects in the non-hierarchical MPT model (mpt_cat.stan)." width="672" />
<p class="caption">
FIGURE 18.8: Individual subjects in the non-hierarchical MPT model (mpt_cat.stan).
</p>
</div>
<p>The hierarchical model does a better job of modeling individual-level variability.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="further-reading-15" class="section level2 hasAnchor" number="18.3">
<h2><span class="header-section-number">18.3</span> Further reading<a href="ch-MPT.html#further-reading-15" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="citation">Koster and McElreath (<a href="#ref-Koster2017" role="doc-biblioref">2017</a>)</span> present a tutorial on multinomial logistic regression/Categorical regression in the context of behavioral ecology and anthropology. Another tutorial on MPTs is presented by <span class="citation">Matzke et al. (<a href="#ref-matzkeBayesianEstimationMultinomial2015" role="doc-biblioref">2015</a>)</span>. For the complete implementation of an MPT relating to aphasia, see <span class="citation">Walker, Hickok, and Fridriksson (<a href="#ref-WalkerEtAl2018" role="doc-biblioref">2018</a>)</span>.
Some examples of cognitive models using MPTs are <span class="citation">M. D. Lee et al. (<a href="#ref-lee2020application" role="doc-biblioref">2020</a>)</span> and <span class="citation">Smith and Batchelder (<a href="#ref-smith2010beta" role="doc-biblioref">2010</a>)</span>.</p>
</div>
<div id="exercises-4" class="section level2 hasAnchor" number="18.4">
<h2><span class="header-section-number">18.4</span> Exercises<a href="ch-MPT.html#exercises-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="exercise">
<p><span id="exr:mult" class="exercise"><strong>Exercise 18.1  </strong></span>Modeling multiple categorical responses.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li>Re-fit the model presented in section <a href="ch-MPT.html#sec-cat">18.1.2</a>, adding the assumption that you have more information about the probability of giving a correct response in the task. Assume that you know that subjects’ answers have around 60% accuracy. Encode this information in the priors with two different degrees of certainty. (Hint: 1. As with the Beta distribution, you can increase the pseudo-counts to increase the amount of information and reduce the “width” of the distribution; compare <span class="math inline">\(Beta(9,1)\)</span> with <span class="math inline">\(Beta(900,100)\)</span>. 2. You’ll need to use a column vector for the Dirichlet concentration parameters. <code>[.., .., ]</code> is a <code>row_vector</code> that can be transposed and converted into a column vector by adding the transposition symbol <code>'</code> after the right bracket.)</li>
<li>What is the difference between the multinomial and categorical parametrizations?</li>
<li>What can we learn about impaired picture naming from the models in <a href="ch-MPT.html#sec-mult">18.1.1</a> and <a href="ch-MPT.html#sec-cat">18.1.2</a>?</li>
</ol>
<div class="exercise">
<p><span id="exr:mpt-mnm" class="exercise"><strong>Exercise 18.2  </strong></span>An alternative MPT to model the picture recognition task.</p>
</div>
<p>Build <em>any</em> alternative tree with four parameters <span class="math inline">\(w\)</span>, <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(z\)</span> to fit the data generated in <a href="ch-MPT.html#sec-mpt-data">18.2.2</a>. Compare the posterior distribution of the auxiliary vector <code>theta</code> (that goes in the <code>multinomial_lpmf</code>) with the one derived in section <a href="ch-MPT.html#sec-mpt-data">18.2.2</a>.</p>
<div class="exercise">
<p><span id="exr:edit-mpt-cat" class="exercise"><strong>Exercise 18.3  </strong></span>A simple MPT model that incorporates phonological complexity in the picture recognition task.</p>
</div>
<p>Edit the the Stan code <code>mpt_cat.stan</code> from <code>bcogsci</code> presented in section <a href="ch-MPT.html#sec-MPT-reg">18.2.3</a> to incorporate the fact that <code>f</code> is now a transformed parameter that depends on the trial information and two new parameters, <span class="math inline">\(\alpha_f\)</span> and <span class="math inline">\(\beta_f\)</span>. The rest of the latent parameters do not need to vary by trial.</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
f&#39;_j &amp;=\alpha_f + complexity_j\cdot \beta_f\\
f_j &amp;= logit^{-1}(f&#39;_j)
\end{aligned}
\end{equation}\]</span></p>
<p>The inverse logit or logistic function is called <code>inv_logit</code> in Stan. Fit the model to the data of <a href="ch-MPT.html#sec-MPT-reg">18.2.3</a> and report the posterior distributions of the latent parameters.</p>
<div class="exercise">
<p><span id="exr:mpt" class="exercise"><strong>Exercise 18.4  </strong></span>A more hierarchical MPT.</p>
</div>
<p>Modify the hierarchical MPT presented in section <a href="ch-MPT.html#sec-MPT-h">18.2.4</a> so that all the parameters are affected by individual differences. Simulate data and fit it. How well can you recover the parameters? You should use the non-centered parameterization for the by-subject adjustments. (Hint: Convergence will be reached much faster if you don’t assume that the adjustment parameters are correlated as in <a href="ch-complexstan.html#sec-uncorrstan">11.1.2</a>, but you could also assume a correlation between all (or some of) the adjustments by using the Cholesky factorization discussed in <a href="ch-complexstan.html#sec-corrstan">11.1.3</a>.)</p>
<div class="exercise">
<p><span id="exr:mpt-adv" class="exercise"><strong>Exercise 18.5  </strong></span><strong>Advanced</strong>: Multinomial processing trees.</p>
</div>
<p>The data set <code>df_source_monitoring</code> in <code>bcogsci</code> contains data from the package <code>psychotools</code> coming from a source-monitoring experiment <span class="citation">(<a href="#ref-batchelder1990multinomial" role="doc-biblioref">Batchelder and Riefer 1990</a>)</span> performed by <span class="citation">Wickelmaier and Zeileis (<a href="#ref-wickelmaier2018using" role="doc-biblioref">2018</a>)</span>.</p>
<p>In this type of experiment, subjects study items from (at least) two different sources, A and B. After the presentation of the study items, subjects are required to classify each item as coming from source A, B, or as new: N (that is, a distractor). In Wickelmaier &amp; Zeileis’ version of the experiment, subjects had to read items either quietly (think) or aloud (say). In the recall task, they wrote them down (write) or read them aloud (say).</p>
<ul>
<li><code>experiment</code>: write-say or think-say</li>
<li><code>age</code>: Age of the respondent in years.</li>
<li><code>gender</code>: Gender of the respondent.</li>
<li><code>subj</code>: Subject id.</li>
<li><code>source</code>: Item source, a, b or b (new)</li>
<li><code>a</code>, <code>b</code>, <code>N</code>: Number of responses for each type of stimuli</li>
</ul>
<p>Fit a multinomial processing tree following Figures <a href="ch-MPT.html#fig:smtikz">18.9</a> and <a href="ch-MPT.html#fig:smtikz2">18.10</a>.
to investigate whether experiment type, age and/or gender affects the different processes assumed in the model.
As in <span class="citation">Batchelder and Riefer (<a href="#ref-batchelder1990multinomial" role="doc-biblioref">1990</a>)</span>, assume that <span class="math inline">\(a = g\)</span> (for identifiability) and that discriminability is equal for both sources (<span class="math inline">\(d_1 = d_2\)</span>).</p>

<div class="figure"><span style="display:block;" id="fig:smtikz"></span>
<img src="bookdown_files/figure-html/smtikz-1.svg" alt="Multinomial processing tree for the source A items from the source monitoring paradigm (Batchelder and Riefer, 1990). \(D_1\) stands for the detectability of source A, \(d_1\) stands for the source discriminabilities for source A items, \(b\) stands for the bias for responding “old” to a nondetected item, \(a\) stands for guessing that a detected but nondiscriminated item belongs to source A, and \(g\) stands for guessing that the item is a source A item." width="672" />
<p class="caption">
FIGURE 18.9: Multinomial processing tree for the source A items from the source monitoring paradigm (Batchelder and Riefer, 1990). <span class="math inline">\(D_1\)</span> stands for the detectability of source A, <span class="math inline">\(d_1\)</span> stands for the source discriminabilities for source A items, <span class="math inline">\(b\)</span> stands for the bias for responding “old” to a nondetected item, <span class="math inline">\(a\)</span> stands for guessing that a detected but nondiscriminated item belongs to source A, and <span class="math inline">\(g\)</span> stands for guessing that the item is a source A item.
</p>
</div>

<div class="figure"><span style="display:block;" id="fig:smtikz2"></span>
<img src="bookdown_files/figure-html/smtikz2-1.svg" alt="Multinomial processing tree for the source B items from source monitoring paradigm (Batchelder and Riefer, 1990). \(D_2\) stand for the detectability of source B items, \(d_2\) stands for the source discriminabilities for source B, \(b\) stands for the bias for responding “old” to a nondetected item, \(a\) stands for guessing that a detected but nondiscriminated item belongs to Source A, and \(g\) stands for guessing that the item is a source A item." width="672" />
<p class="caption">
FIGURE 18.10: Multinomial processing tree for the source B items from source monitoring paradigm (Batchelder and Riefer, 1990). <span class="math inline">\(D_2\)</span> stand for the detectability of source B items, <span class="math inline">\(d_2\)</span> stands for the source discriminabilities for source B, <span class="math inline">\(b\)</span> stands for the bias for responding “old” to a nondetected item, <span class="math inline">\(a\)</span> stands for guessing that a detected but nondiscriminated item belongs to Source A, and <span class="math inline">\(g\)</span> stands for guessing that the item is a source A item.
</p>
</div>

<div class="figure"><span style="display:block;" id="fig:sm-tikz3"></span>
<img src="bookdown_files/figure-html/sm-tikz3-1.svg" alt="Multinomial processing tree for the new items in the source monitoring paradigm (Batchelder and Riefer, 1990). \(b\) stands for the bias for responding “old” to a nondetected item, \(a\) stands for guessing that a detected but nondiscriminated item belongs to source A, and \(g\) stands for guessing that the item is a source A item." width="672" />
<p class="caption">
FIGURE 18.11: Multinomial processing tree for the new items in the source monitoring paradigm (Batchelder and Riefer, 1990). <span class="math inline">\(b\)</span> stands for the bias for responding “old” to a nondetected item, <span class="math inline">\(a\)</span> stands for guessing that a detected but nondiscriminated item belongs to source A, and <span class="math inline">\(g\)</span> stands for guessing that the item is a source A item.
</p>
</div>
<p>Notice the following:</p>
<ul>
<li>The data are aggregated at the level of source, so you should use <code>multinomial_lpmf</code> for every row of the data set rather than <code>categorical_lpmf()</code>.</li>
<li>In contrast to the previous example, <code>source</code> determines three different trees, this means that the parameter <code>theta</code> has to be defined in relationship to the item source.</li>
<li>All the predictors are between subject, this means that only a by-intercept adjustment (for every latent process) is possible.</li>
</ul>
<p>If you want some basis to start with, you can have a look at the incomplete code in <code>source.stan</code>, by typing the following in R:</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1072-1"><a href="ch-MPT.html#cb1072-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">readLines</span>(<span class="fu">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb1072-2"><a href="ch-MPT.html#cb1072-2" aria-hidden="true" tabindex="-1"></a>                     <span class="st">&quot;source.stan&quot;</span>,</span>
<span id="cb1072-3"><a href="ch-MPT.html#cb1072-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">package =</span> <span class="st">&quot;bcogsci&quot;</span>)),</span>
<span id="cb1072-4"><a href="ch-MPT.html#cb1072-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-batchelder1990multinomial" class="csl-entry">
Batchelder, William H, and David M Riefer. 1990. <span>“Multinomial Processing Models of Source Monitoring.”</span> <em>Psychological Review</em> 97 (4): 548.
</div>
<div id="ref-BatchelderRiefer1999" class="csl-entry">
———. 1999. <span>“Theoretical and Empirical Review of Multinomial Process Tree Modeling.”</span> <em>Psychonomic Bulletin &amp; Review</em> 6 (1): 57–86.
</div>
<div id="ref-Cooketal2006" class="csl-entry">
Cook, Samantha R, Andrew Gelman, and Donald B Rubin. 2006. <span>“Validation of Software for <span>Bayesian</span> Models Using Posterior Quantiles.”</span> <em>Journal of Computational and Graphical Statistics</em> 15 (3): 675–92. <a href="https://doi.org/10.1198/106186006X136976">https://doi.org/10.1198/106186006X136976</a>.
</div>
<div id="ref-damasio1992aphasia" class="csl-entry">
Damasio, Antonio R. 1992. <span>“Aphasia.”</span> <em>New England Journal of Medicine</em> 326 (8): 531–39.
</div>
<div id="ref-Koster2017" class="csl-entry">
Koster, Jeremy, and Richard McElreath. 2017. <span>“Multinomial Analysis of Behavior: <span>Statistical</span> Methods.”</span> <em>Behavioral Ecology and Sociobiology</em> 71 (9): 138. <a href="https://doi.org/10.1007/s00265-017-2363-8">https://doi.org/10.1007/s00265-017-2363-8</a>.
</div>
<div id="ref-lee2020application" class="csl-entry">
Lee, Michael D., Jason R Bock, Isaiah Cushman, and William R Shankle. 2020. <span>“An Application of Multinomial Processing Tree Models and <span>B</span>ayesian Methods to Understanding Memory Impairment.”</span> <em>Journal of Mathematical Psychology</em> 95: 102328.
</div>
<div id="ref-matzkeBayesianEstimationMultinomial2015" class="csl-entry">
Matzke, Dora, Conor V. Dolan, William H. Batchelder, and Eric-Jan Wagenmakers. 2015. <span>“Bayesian <span>Estimation</span> of <span>Multinomial Processing Tree Models</span> with <span>Heterogeneity</span> in <span>Participants</span> and <span>Items</span>.”</span> <em>Psychometrika</em> 80 (1): 205–35. <a href="https://doi.org/10.1007/s11336-013-9374-9">https://doi.org/10.1007/s11336-013-9374-9</a>.
</div>
<div id="ref-schad2020toward" class="csl-entry">
Schad, Daniel J., Michael J. Betancourt, and Shravan Vasishth. 2020. <span>“Toward a Principled <span>Bayesian</span> Workflow in Cognitive Science.”</span> <em>Psychological Methods</em> 26 (1): 103–26.
</div>
<div id="ref-smith2010beta" class="csl-entry">
Smith, Jared B, and William H Batchelder. 2010. <span>“Beta-<span>MPT</span>: <span>M</span>ultinomial Processing Tree Models for Addressing Individual Differences.”</span> <em>Journal of Mathematical Psychology</em> 54 (1): 167–83.
</div>
<div id="ref-talts2018validating" class="csl-entry">
Talts, Sean, Michael J. Betancourt, Daniel Simpson, Aki Vehtari, and Andrew Gelman. 2018. <span>“Validating Bayesian Inference Algorithms with Simulation-Based Calibration.”</span> <em>arXiv Preprint arXiv:1804.06788</em>.
</div>
<div id="ref-WalkerEtAl2018" class="csl-entry">
Walker, Grant M, Gregory Hickok, and Julius Fridriksson. 2018. <span>“A Cognitive Psychometric Model for Assessment of Picture Naming Abilities in Aphasia.”</span> <em>Psychological Assessment</em> 6: 809–26. <a href="https://doi.org/10.1037/pas0000529">https://doi.org/10.1037/pas0000529</a>.
</div>
<div id="ref-wickelmaier2018using" class="csl-entry">
Wickelmaier, Florian, and Achim Zeileis. 2018. <span>“Using Recursive Partitioning to Account for Parameter Heterogeneity in Multinomial Processing Tree Models.”</span> <em>Behavior Research Methods</em> 50 (3): 1217–33.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-cogmod.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-mixture.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
